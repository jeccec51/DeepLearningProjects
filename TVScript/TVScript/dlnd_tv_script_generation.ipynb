{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TV Script Generation\n",
    "\n",
    "In this project, you'll generate your own [Seinfeld](https://en.wikipedia.org/wiki/Seinfeld) TV scripts using RNNs.  You'll be using part of the [Seinfeld dataset](https://www.kaggle.com/thec03u5/seinfeld-chronicles#scripts.csv) of scripts from 9 seasons.  The Neural Network you'll build will generate a new ,\"fake\" TV script, based on patterns it recognizes in this training data.\n",
    "\n",
    "## Get the Data\n",
    "\n",
    "The data is already provided for you in `./data/Seinfeld_Scripts.txt` and you're encouraged to open that file and look at the text. \n",
    ">* As a first step, we'll load in this data and look at some samples. \n",
    "* Then, you'll be tasked with defining and training an RNN to generate a new script!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# load in data\n",
    "import helper\n",
    "data_dir = './data/Seinfeld_Scripts.txt'\n",
    "text = helper.load_data(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "Play around with `view_line_range` to view different parts of the data. This will give you a sense of the data you'll be working with. You can see, for example, that it is all lowercase text, and each new line of dialogue is separated by a newline character `\\n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 46367\n",
      "Number of lines: 109233\n",
      "Average number of words in each line: 5.544240293684143\n",
      "\n",
      "The lines 0 to 10:\n",
      "jerry: do you know what this is all about? do you know, why were here? to be out, this is out...and out is one of the single most enjoyable experiences of life. people...did you ever hear people talking about we should go out? this is what theyre talking about...this whole thing, were all out now, no one is home. not one person here is home, were all out! there are people trying to find us, they dont know where we are. (on an imaginary phone) did you ring?, i cant find him. where did he go? he didnt tell me where he was going. he must have gone out. you wanna go out you get ready, you pick out the clothes, right? you take the shower, you get all ready, get the cash, get your friends, the car, the spot, the reservation...then youre standing around, what do you do? you go we gotta be getting back. once youre out, you wanna get back! you wanna go to sleep, you wanna get up, you wanna go out again tomorrow, right? where ever you are in life, its my feeling, youve gotta go. \n",
      "\n",
      "jerry: (pointing at georges shirt) see, to me, that button is in the worst possible spot. the second button literally makes or breaks the shirt, look at it. its too high! its in no-mans-land. you look like you live with your mother. \n",
      "\n",
      "george: are you through? \n",
      "\n",
      "jerry: you do of course try on, when you buy? \n",
      "\n",
      "george: yes, it was purple, i liked it, i dont actually recall considering the buttons. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_line_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "\n",
    "lines = text.split('\\n')\n",
    "print('Number of lines: {}'.format(len(lines)))\n",
    "word_count_line = [len(line.split()) for line in lines]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_line)))\n",
    "\n",
    "print()\n",
    "print('The lines {} to {}:'.format(*view_line_range))\n",
    "print('\\n'.join(text.split('\\n')[view_line_range[0]:view_line_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Implement Pre-processing Functions\n",
    "The first thing to do to any dataset is pre-processing.  Implement the following pre-processing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following **tuple** `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import problem_unittests as tests\n",
    "from collections import Counter\n",
    "\n",
    "def create_lookup_tables(words):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param words: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    word_counts = Counter(words)\n",
    "    # sorting the words from most to least frequent in text occurrence\n",
    "    sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "    # create int_to_vocab dictionaries\n",
    "    int_to_vocab = {ii: word for ii, word in enumerate(sorted_vocab)}\n",
    "    vocab_to_int = {word: ii for ii, word in int_to_vocab.items()}\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks can create multiple ids for the same word. For example, \"bye\" and \"bye!\" would generate two different word ids.\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( **.** )\n",
    "- Comma ( **,** )\n",
    "- Quotation Mark ( **\"** )\n",
    "- Semicolon ( **;** )\n",
    "- Exclamation mark ( **!** )\n",
    "- Question mark ( **?** )\n",
    "- Left Parentheses ( **(** )\n",
    "- Right Parentheses ( **)** )\n",
    "- Dash ( **-** )\n",
    "- Return ( **\\n** )\n",
    "\n",
    "This dictionary will be used to tokenize the symbols and add the delimiter (space) around it.  This separates each symbols as its own word, making it easier for the neural network to predict the next word. Make sure you don't use a value that could be confused as a word; for example, instead of using the value \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenized dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    punctuation_lookup = {\n",
    "        '.': '<PERIOD>',\n",
    "        ',': '<COMMA>',\n",
    "        '\"': '<QUOTATION_MARK>',\n",
    "        ';': '<SEMICOLON>',\n",
    "        '!': '<EXCLAMATION_MARK>',\n",
    "        '?': '<QUESTION_MARK>',\n",
    "        '(': '<LEFT_PAREN>',\n",
    "        ')': '<RIGHT_PAREN>',\n",
    "        '-': '<DASH>',\n",
    "        '\\n': '<NEW_LINE>',\n",
    "    }\n",
    "    return punctuation_lookup\n",
    "        \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process all the data and save it\n",
    "\n",
    "Running the code cell below will pre-process all the data and save it to file. You're encouraged to lok at the code for `preprocess_and_save_data` in the `helpers.py` file to see what it's doing in detail, but you do not need to change this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# pre-process training data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "In this section, you'll build the components necessary to build an RNN by implementing the RNN Module and forward and backpropagation functions.\n",
    "\n",
    "### Check Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "\n",
    "# Check for a GPU\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('No GPU found. Please use a GPU to train your neural network.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "Let's start with the preprocessed input data. We'll use [TensorDataset](http://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset) to provide a known format to our dataset; in combination with [DataLoader](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader), it will handle batching, shuffling, and other dataset iteration functions.\n",
    "\n",
    "You can create data with TensorDataset by passing in feature and target tensors. Then create a DataLoader as usual.\n",
    "```\n",
    "data = TensorDataset(feature_tensors, target_tensors)\n",
    "data_loader = torch.utils.data.DataLoader(data, \n",
    "                                          batch_size=batch_size)\n",
    "```\n",
    "\n",
    "### Batching\n",
    "Implement the `batch_data` function to batch `words` data into chunks of size `batch_size` using the `TensorDataset` and `DataLoader` classes.\n",
    "\n",
    ">You can batch words using the DataLoader, but it will be up to you to create `feature_tensors` and `target_tensors` of the correct size and content for a given `sequence_length`.\n",
    "\n",
    "For example, say we have these as input:\n",
    "```\n",
    "words = [1, 2, 3, 4, 5, 6, 7]\n",
    "sequence_length = 4\n",
    "```\n",
    "\n",
    "Your first `feature_tensor` should contain the values:\n",
    "```\n",
    "[1, 2, 3, 4]\n",
    "```\n",
    "And the corresponding `target_tensor` should just be the next \"word\"/tokenized word value:\n",
    "```\n",
    "5\n",
    "```\n",
    "This should continue with the second `feature_tensor`, `target_tensor` being:\n",
    "```\n",
    "[2, 3, 4, 5]  # features\n",
    "6             # target\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "def batch_data(words, sequence_length, batch_size):\n",
    "    \"\"\"\n",
    "     Batch the neural network data using DataLoader\n",
    "    :param words: The word ids of the TV scripts\n",
    "    :param sequence_length: The sequence length of each batch\n",
    "    :param batch_size: The size of each batch; the number of sequences in a batch\n",
    "    :return: data_loaders: DataLoader with batched data\n",
    "    \"\"\"\n",
    "    n_batches = len(words) // batch_size\n",
    "    # Filter the residual data so that we have only full atches\n",
    "    words = words[:n_batches * batch_size]\n",
    "    future_tensors, targets = [], []\n",
    "    for ii in range(0, len(words) - sequence_length):\n",
    "        start = ii\n",
    "        end = sequence_length + ii\n",
    "        data = words[start:end]\n",
    "        future_tensors.append(data)\n",
    "        if end  >= (len(words)):\n",
    "            target_word = words[0]\n",
    "        else:\n",
    "            target_word = words[end]\n",
    "        targets.append(target_word)\n",
    "    # create Tensor datasets\n",
    "    data = TensorDataset(torch.from_numpy(np.asarray(future_tensors)), torch.from_numpy(np.asarray(targets)))\n",
    "    data_loader = DataLoader(data, shuffle=False, batch_size=batch_size)\n",
    "    return data_loader\n",
    "\n",
    "# there is no test for this function, but you are encouraged to create\n",
    "# print statements and tests of your own\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test your dataloader \n",
    "\n",
    "You'll have to modify this code to test a batching function, but it should look fairly similar.\n",
    "\n",
    "Below, we're generating some test text data and defining a dataloader using the function you defined, above. Then, we are getting some sample batch of inputs `sample_x` and targets `sample_y` from our dataloader.\n",
    "\n",
    "Your code should return something like the following (likely in a different order, if you shuffled your data):\n",
    "\n",
    "```\n",
    "torch.Size([10, 5])\n",
    "tensor([[ 28,  29,  30,  31,  32],\n",
    "        [ 21,  22,  23,  24,  25],\n",
    "        [ 17,  18,  19,  20,  21],\n",
    "        [ 34,  35,  36,  37,  38],\n",
    "        [ 11,  12,  13,  14,  15],\n",
    "        [ 23,  24,  25,  26,  27],\n",
    "        [  6,   7,   8,   9,  10],\n",
    "        [ 38,  39,  40,  41,  42],\n",
    "        [ 25,  26,  27,  28,  29],\n",
    "        [  7,   8,   9,  10,  11]])\n",
    "\n",
    "torch.Size([10])\n",
    "tensor([ 33,  26,  22,  39,  16,  28,  11,  43,  30,  12])\n",
    "```\n",
    "\n",
    "### Sizes\n",
    "Your sample_x should be of size `(batch_size, sequence_length)` or (10, 5) in this case and sample_y should just have one dimension: batch_size (10). \n",
    "\n",
    "### Values\n",
    "\n",
    "You should also notice that the targets, sample_y, are the *next* value in the ordered test_text data. So, for an input sequence `[ 28,  29,  30,  31,  32]` that ends with the value `32`, the corresponding output should be `33`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5])\n",
      "tensor([[ 0,  1,  2,  3,  4],\n",
      "        [ 1,  2,  3,  4,  5],\n",
      "        [ 2,  3,  4,  5,  6],\n",
      "        [ 3,  4,  5,  6,  7],\n",
      "        [ 4,  5,  6,  7,  8],\n",
      "        [ 5,  6,  7,  8,  9],\n",
      "        [ 6,  7,  8,  9, 10],\n",
      "        [ 7,  8,  9, 10, 11],\n",
      "        [ 8,  9, 10, 11, 12],\n",
      "        [ 9, 10, 11, 12, 13]], dtype=torch.int32)\n",
      "\n",
      "torch.Size([10])\n",
      "tensor([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# test dataloader\n",
    "\n",
    "test_text = range(50)\n",
    "t_loader = batch_data(test_text, sequence_length=5, batch_size=10)\n",
    "data_iter = iter(t_loader)\n",
    "sample_x, sample_y = data_iter.next()\n",
    "print(sample_x.shape)\n",
    "print(sample_x)\n",
    "print()\n",
    "print(sample_y.shape)\n",
    "print(sample_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build the Neural Network\n",
    "Implement an RNN using PyTorch's [Module class](http://pytorch.org/docs/master/nn.html#torch.nn.Module). You may choose to use a GRU or an LSTM. To complete the RNN, you'll have to implement the following functions for the class:\n",
    " - `__init__` - The initialize function. \n",
    " - `init_hidden` - The initialization function for an LSTM/GRU hidden state\n",
    " - `forward` - Forward propagation function.\n",
    " \n",
    "The initialize function should create the layers of the neural network and save them to the class. The forward propagation function will use these layers to run forward propagation and generate an output and a hidden state.\n",
    "\n",
    "**The output of this model should be the *last* batch of word scores** after a complete sequence has been processed. That is, for each input sequence of words, we only want to output the word scores for a single, most likely, next word.\n",
    "\n",
    "### Hints\n",
    "\n",
    "1. Make sure to stack the outputs of the lstm to pass to your fully-connected layer, you can do this with `lstm_output = lstm_output.contiguous().view(-1, self.hidden_dim)`\n",
    "2. You can get the last batch of word scores by shaping the output of the final, fully-connected layer like so:\n",
    "\n",
    "```\n",
    "# reshape into (batch_size, seq_length, output_size)\n",
    "output = output.view(batch_size, -1, self.output_size)\n",
    "# get last batch\n",
    "out = output[:, -1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, output_size, embed_dim, hidden_dim, n_layers, dropout=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the PyTorch RNN Module\n",
    "        :param vocab_size: The number of input dimensions of the neural network (the size of the vocabulary)\n",
    "        :param output_size: The number of output dimensions of the neural network\n",
    "        :param embed_dim: The size of embeddings, should you choose to use them\n",
    "        :param hidden_dim: The size of the hidden layer outputs\n",
    "        :param dropout: dropout to add in between LSTM/GRU layers\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        # Internal Variables\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # Layers\n",
    "        # embedding and LSTM layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, n_layers,\n",
    "                            dropout=dropout, batch_first=True)\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # linear  layers\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "    def forward(self, nn_input, hidden):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param nn_input: The input to the neural network\n",
    "        :param hidden: The hidden state\n",
    "        :return: Two Tensors, the output of the neural network and the latest hidden state\n",
    "        \"\"\"\n",
    "        # nn_input = nn_input.long()\n",
    "        nn_input = nn_input.to(torch.int64)\n",
    "        batch_size = nn_input.size(0)\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(nn_input)\n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fc(out)\n",
    "        # reshape into (batch_size, seq_length, output_size)\n",
    "        out = out.view(batch_size, -1, self.output_size)\n",
    "        out = out[:, -1]  # get last batch of labels\n",
    "        # return one batch of output word scores and the hidden state\n",
    "        return out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Initialize the hidden state of an LSTM/GRU\n",
    "        :param batch_size: The batch_size of the hidden state\n",
    "        :return: hidden state of dims (n_layers, batch_size, hidden_dim)\n",
    "        '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if  train_on_gpu:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_rnn(RNN, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define forward and backpropagation\n",
    "\n",
    "Use the RNN class you implemented to apply forward and back propagation. This function will be called, iteratively, in the training loop as follows:\n",
    "```\n",
    "loss = forward_back_prop(decoder, decoder_optimizer, criterion, inp, target)\n",
    "```\n",
    "\n",
    "And it should return the average loss over a batch and the hidden state returned by a call to `RNN(inp, hidden)`. Recall that you can get this loss by computing it, as usual, and calling `loss.item()`.\n",
    "\n",
    "**If a GPU is available, you should move your data to that GPU device, here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def forward_back_prop(rnn, optimizer, criterion, inp, target, hidden):\n",
    "    \"\"\"\n",
    "     Forward and backward propagation on the neural network\n",
    "    :param train_on_gpu: Flag to indicate of GPU is available\n",
    "    :param hidden: Hidden state output\n",
    "    :param rnn: The PyTorch Module that holds the neural network\n",
    "    :param optimizer: The PyTorch optimizer for the neural network\n",
    "    :param criterion: The PyTorch loss function\n",
    "    :param inp: A batch of input to the neural network\n",
    "    :param target: The target output for the batch of input\n",
    "    :return: The loss and the latest hidden state Tensor\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    # move data to GPU, if available\n",
    "\n",
    "    # perform backpropagation and optimization\n",
    "\n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    gradient_clip = 5  # gradient clipping\n",
    "\n",
    "    # Creating new variables for the hidden state\n",
    "    hidden = tuple([each.data for each in hidden])\n",
    "    # move data to GPU, if available\n",
    "    if train_on_gpu:\n",
    "        inp, target = inp.cuda(), target.cuda()\n",
    "    # zero accumulated gradients\n",
    "    rnn.zero_grad()\n",
    "    # perform backpropagation and optimization\n",
    "    output, hidden = rnn(inp, hidden)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(rnn.parameters(), gradient_clip)\n",
    "    optimizer.step()\n",
    "    # return the loss over a batch and the hidden state produced by our model\n",
    "    return loss.item(), hidden\n",
    "\n",
    "\n",
    "# Note that these tests aren't completely extensive.\n",
    "# they are here to act as general checks on the expected outputs of your functions\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_forward_back_prop(RNN, forward_back_prop, train_on_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "\n",
    "With the structure of the network complete and data ready to be fed in the neural network, it's time to train it.\n",
    "\n",
    "### Train Loop\n",
    "\n",
    "The training loop is implemented for you in the `train_decoder` function. This function will train the network over all the batches for the number of epochs given. The model progress will be shown every number of batches. This number is set with the `show_every_n_batches` parameter. You'll set this parameter along with other parameters in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "def train_rnn(rnn, batch_size, optimizer, criterion, n_epochs, show_every_n_batches=100):\n",
    "    batch_losses = []\n",
    "    rnn.train()\n",
    "\n",
    "    print(\"Training for %d epoch(s)...\" % n_epochs)\n",
    "    for epoch_i in range(1, n_epochs + 1):\n",
    "        \n",
    "        # initialize hidden state\n",
    "        hidden = rnn.init_hidden(batch_size)\n",
    "        \n",
    "        for batch_i, (inputs, labels) in enumerate(train_loader, 1):\n",
    "            \n",
    "            # make sure you iterate over completely full batches, only\n",
    "            n_batches = len(train_loader.dataset)//batch_size\n",
    "            if(batch_i > n_batches):\n",
    "                break\n",
    "            \n",
    "            # forward, back prop\n",
    "            loss, hidden = forward_back_prop(rnn, optimizer, criterion, inputs, labels, hidden)          \n",
    "            # record loss\n",
    "            batch_losses.append(loss)\n",
    "\n",
    "            # printing loss stats\n",
    "            if batch_i % show_every_n_batches == 0:\n",
    "                print('Epoch: {:>4}/{:<4}  Loss: {}\\n'.format(\n",
    "                    epoch_i, n_epochs, np.average(batch_losses)))\n",
    "                batch_losses = []\n",
    "        helper.save_model('./save/trained_rnn_epoch', rnn)\n",
    "        print('Model Trained and Saved')\n",
    "\n",
    "    # returns a trained rnn\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "Set and train the neural network with the following parameters:\n",
    "- Set `sequence_length` to the length of a sequence.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `num_epochs` to the number of epochs to train for.\n",
    "- Set `learning_rate` to the learning rate for an Adam optimizer.\n",
    "- Set `vocab_size` to the number of uniqe tokens in our vocabulary.\n",
    "- Set `output_size` to the desired size of the output.\n",
    "- Set `embedding_dim` to the embedding dimension; smaller than the vocab_size.\n",
    "- Set `hidden_dim` to the hidden dimension of your RNN.\n",
    "- Set `n_layers` to the number of layers/cells in your RNN.\n",
    "- Set `show_every_n_batches` to the number of batches at which the neural network should print progress.\n",
    "\n",
    "If the network isn't getting the desired results, tweak these parameters and/or the layers in the `RNN` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "# Sequence Length\n",
    "sequence_length =   32# of words in a sequence\n",
    "# Batch Size\n",
    "batch_size = 128\n",
    "\n",
    "# data loader - do not change\n",
    "train_loader = batch_data(int_text, sequence_length, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "# Number of Epochs\n",
    "num_epochs = 10\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Model parameters\n",
    "# Vocab size\n",
    "vocab_size = len(vocab_to_int)\n",
    "# Output size\n",
    "output_size = len(vocab_to_int)\n",
    "# Embedding Dimension\n",
    "embedding_dim = 200\n",
    "# Hidden Dimension\n",
    "hidden_dim = 1024\n",
    "# Number of RNN Layers\n",
    "n_layers = 2\n",
    "\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "In the next cell, you'll train the neural network on the pre-processed data.  If you have a hard time getting a good loss, you may consider changing your hyperparameters. In general, you may get better results with larger hidden and n_layer dimensions, but larger models take a longer time to train. \n",
    "> **You should aim for a loss less than 3.5.** \n",
    "\n",
    "You should also experiment with different sequence lengths, which determine the size of the long range dependencies that a model can learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epoch(s)...\n",
      "Epoch:    1/10    Loss: 7.008833694458008\n",
      "\n",
      "Epoch:    1/10    Loss: 6.115194435119629\n",
      "\n",
      "Epoch:    1/10    Loss: 5.7657509040832515\n",
      "\n",
      "Epoch:    1/10    Loss: 5.8467887496948245\n",
      "\n",
      "Epoch:    1/10    Loss: 5.445368461608886\n",
      "\n",
      "Epoch:    1/10    Loss: 5.442215938568115\n",
      "\n",
      "Epoch:    1/10    Loss: 5.400918922424316\n",
      "\n",
      "Epoch:    1/10    Loss: 5.244353694915771\n",
      "\n",
      "Epoch:    1/10    Loss: 5.305827827453613\n",
      "\n",
      "Epoch:    1/10    Loss: 5.006659746170044\n",
      "\n",
      "Epoch:    1/10    Loss: 5.193786563873291\n",
      "\n",
      "Epoch:    1/10    Loss: 5.053718776702881\n",
      "\n",
      "Epoch:    1/10    Loss: 5.145954504013061\n",
      "\n",
      "Epoch:    1/10    Loss: 4.766558475494385\n",
      "\n",
      "Epoch:    1/10    Loss: 5.032445430755615\n",
      "\n",
      "Epoch:    1/10    Loss: 5.0633285617828365\n",
      "\n",
      "Epoch:    1/10    Loss: 4.790766859054566\n",
      "\n",
      "Epoch:    1/10    Loss: 5.184553775787354\n",
      "\n",
      "Epoch:    1/10    Loss: 5.17572865486145\n",
      "\n",
      "Epoch:    1/10    Loss: 5.226237907409668\n",
      "\n",
      "Epoch:    1/10    Loss: 4.866916236877441\n",
      "\n",
      "Epoch:    1/10    Loss: 4.85487138748169\n",
      "\n",
      "Epoch:    1/10    Loss: 5.1109814453125\n",
      "\n",
      "Epoch:    1/10    Loss: 4.926777448654175\n",
      "\n",
      "Epoch:    1/10    Loss: 4.867613162994385\n",
      "\n",
      "Epoch:    1/10    Loss: 5.2757354164123536\n",
      "\n",
      "Epoch:    1/10    Loss: 4.734065780639648\n",
      "\n",
      "Epoch:    1/10    Loss: 4.9821852016448975\n",
      "\n",
      "Epoch:    1/10    Loss: 4.794473581314087\n",
      "\n",
      "Epoch:    1/10    Loss: 4.704879169464111\n",
      "\n",
      "Epoch:    1/10    Loss: 5.134649600982666\n",
      "\n",
      "Epoch:    1/10    Loss: 4.647923889160157\n",
      "\n",
      "Epoch:    1/10    Loss: 5.20726390838623\n",
      "\n",
      "Epoch:    1/10    Loss: 4.980920457839966\n",
      "\n",
      "Epoch:    1/10    Loss: 4.652392263412476\n",
      "\n",
      "Epoch:    1/10    Loss: 4.552236204147339\n",
      "\n",
      "Epoch:    1/10    Loss: 4.373485898971557\n",
      "\n",
      "Epoch:    1/10    Loss: 4.391271238327026\n",
      "\n",
      "Epoch:    1/10    Loss: 4.530721788406372\n",
      "\n",
      "Epoch:    1/10    Loss: 4.648700685501098\n",
      "\n",
      "Epoch:    1/10    Loss: 4.438824272155761\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5496500205993655\n",
      "\n",
      "Epoch:    1/10    Loss: 4.7849827003479\n",
      "\n",
      "Epoch:    1/10    Loss: 4.648103866577149\n",
      "\n",
      "Epoch:    1/10    Loss: 5.107406225204468\n",
      "\n",
      "Epoch:    1/10    Loss: 4.6902847003936765\n",
      "\n",
      "Epoch:    1/10    Loss: 4.623515043258667\n",
      "\n",
      "Epoch:    1/10    Loss: 4.734853610992432\n",
      "\n",
      "Epoch:    1/10    Loss: 4.259838619232178\n",
      "\n",
      "Epoch:    1/10    Loss: 4.583461036682129\n",
      "\n",
      "Epoch:    1/10    Loss: 4.659172677993775\n",
      "\n",
      "Epoch:    1/10    Loss: 4.482334823608398\n",
      "\n",
      "Epoch:    1/10    Loss: 4.695341539382935\n",
      "\n",
      "Epoch:    1/10    Loss: 4.573246946334839\n",
      "\n",
      "Epoch:    1/10    Loss: 4.577986326217651\n",
      "\n",
      "Epoch:    1/10    Loss: 4.610907506942749\n",
      "\n",
      "Epoch:    1/10    Loss: 4.334644727706909\n",
      "\n",
      "Epoch:    1/10    Loss: 4.234008903503418\n",
      "\n",
      "Epoch:    1/10    Loss: 4.258339128494263\n",
      "\n",
      "Epoch:    1/10    Loss: 4.416790666580201\n",
      "\n",
      "Epoch:    1/10    Loss: 4.717230644226074\n",
      "\n",
      "Epoch:    1/10    Loss: 4.649444646835327\n",
      "\n",
      "Epoch:    1/10    Loss: 4.577000226974487\n",
      "\n",
      "Epoch:    1/10    Loss: 4.113821611404419\n",
      "\n",
      "Epoch:    1/10    Loss: 4.273153476715088\n",
      "\n",
      "Epoch:    1/10    Loss: 4.348300371170044\n",
      "\n",
      "Epoch:    1/10    Loss: 4.274195909500122\n",
      "\n",
      "Epoch:    1/10    Loss: 4.637589912414551\n",
      "\n",
      "Epoch:    1/10    Loss: 4.298995542526245\n",
      "\n",
      "Epoch:    1/10    Loss: 4.318289194107056\n",
      "\n",
      "Epoch:    1/10    Loss: 4.450721349716186\n",
      "\n",
      "Epoch:    1/10    Loss: 4.583599500656128\n",
      "\n",
      "Epoch:    1/10    Loss: 4.502915992736816\n",
      "\n",
      "Epoch:    1/10    Loss: 4.480564947128296\n",
      "\n",
      "Epoch:    1/10    Loss: 4.404851322174072\n",
      "\n",
      "Epoch:    1/10    Loss: 4.242915143966675\n",
      "\n",
      "Epoch:    1/10    Loss: 4.579592313766479\n",
      "\n",
      "Epoch:    1/10    Loss: 4.285290632247925\n",
      "\n",
      "Epoch:    1/10    Loss: 4.287222185134888\n",
      "\n",
      "Epoch:    1/10    Loss: 4.834526853561401\n",
      "\n",
      "Epoch:    1/10    Loss: 4.263524303436279\n",
      "\n",
      "Epoch:    1/10    Loss: 4.96223741531372\n",
      "\n",
      "Epoch:    1/10    Loss: 4.683350763320923\n",
      "\n",
      "Epoch:    1/10    Loss: 4.345583372116089\n",
      "\n",
      "Epoch:    1/10    Loss: 4.329572439193726\n",
      "\n",
      "Epoch:    1/10    Loss: 4.374798126220703\n",
      "\n",
      "Epoch:    1/10    Loss: 4.591806125640869\n",
      "\n",
      "Epoch:    1/10    Loss: 4.755008754730224\n",
      "\n",
      "Epoch:    1/10    Loss: 4.600891714096069\n",
      "\n",
      "Epoch:    1/10    Loss: 4.326919937133789\n",
      "\n",
      "Epoch:    1/10    Loss: 4.518862648010254\n",
      "\n",
      "Epoch:    1/10    Loss: 4.341280612945557\n",
      "\n",
      "Epoch:    1/10    Loss: 4.429384250640869\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2659939193725585\n",
      "\n",
      "Epoch:    1/10    Loss: 4.423844709396362\n",
      "\n",
      "Epoch:    1/10    Loss: 4.474244880676269\n",
      "\n",
      "Epoch:    1/10    Loss: 4.407146272659301\n",
      "\n",
      "Epoch:    1/10    Loss: 4.578399572372437\n",
      "\n",
      "Epoch:    1/10    Loss: 4.093289966583252\n",
      "\n",
      "Epoch:    1/10    Loss: 4.1879117298126225\n",
      "\n",
      "Epoch:    1/10    Loss: 4.489905319213867\n",
      "\n",
      "Epoch:    1/10    Loss: 4.301831197738648\n",
      "\n",
      "Epoch:    1/10    Loss: 4.323977222442627\n",
      "\n",
      "Epoch:    1/10    Loss: 4.283410196304321\n",
      "\n",
      "Epoch:    1/10    Loss: 4.694136333465576\n",
      "\n",
      "Epoch:    1/10    Loss: 4.851298217773437\n",
      "\n",
      "Epoch:    1/10    Loss: 4.601886749267578\n",
      "\n",
      "Epoch:    1/10    Loss: 4.337072668075561\n",
      "\n",
      "Epoch:    1/10    Loss: 4.25522216796875\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5699473476409915\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5255725288391115\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4396054077148435\n",
      "\n",
      "Epoch:    1/10    Loss: 4.323243579864502\n",
      "\n",
      "Epoch:    1/10    Loss: 4.41634783744812\n",
      "\n",
      "Epoch:    1/10    Loss: 4.689477653503418\n",
      "\n",
      "Epoch:    1/10    Loss: 4.639755611419678\n",
      "\n",
      "Epoch:    1/10    Loss: 4.599239139556885\n",
      "\n",
      "Epoch:    1/10    Loss: 4.352359247207642\n",
      "\n",
      "Epoch:    1/10    Loss: 4.608395586013794\n",
      "\n",
      "Epoch:    1/10    Loss: 4.6031053924560545\n",
      "\n",
      "Epoch:    1/10    Loss: 4.562484760284423\n",
      "\n",
      "Epoch:    1/10    Loss: 4.394158811569214\n",
      "\n",
      "Epoch:    1/10    Loss: 4.575289077758789\n",
      "\n",
      "Epoch:    1/10    Loss: 4.431913566589356\n",
      "\n",
      "Epoch:    1/10    Loss: 4.344661626815796\n",
      "\n",
      "Epoch:    1/10    Loss: 4.104528837203979\n",
      "\n",
      "Epoch:    1/10    Loss: 4.535216121673584\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4130799770355225\n",
      "\n",
      "Epoch:    1/10    Loss: 4.364744567871094\n",
      "\n",
      "Epoch:    1/10    Loss: 4.550856304168701\n",
      "\n",
      "Epoch:    1/10    Loss: 4.595829200744629\n",
      "\n",
      "Epoch:    1/10    Loss: 4.20223635673523\n",
      "\n",
      "Epoch:    1/10    Loss: 4.432158899307251\n",
      "\n",
      "Epoch:    1/10    Loss: 4.372745752334595\n",
      "\n",
      "Epoch:    1/10    Loss: 4.476727361679077\n",
      "\n",
      "Epoch:    1/10    Loss: 4.349167032241821\n",
      "\n",
      "Epoch:    1/10    Loss: 4.322580146789551\n",
      "\n",
      "Epoch:    1/10    Loss: 4.377601947784424\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3226472187042235\n",
      "\n",
      "Epoch:    1/10    Loss: 4.193933038711548\n",
      "\n",
      "Epoch:    1/10    Loss: 4.14923581123352\n",
      "\n",
      "Epoch:    1/10    Loss: 4.173138542175293\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3092616748809816\n",
      "\n",
      "Epoch:    1/10    Loss: 4.474265394210815\n",
      "\n",
      "Epoch:    1/10    Loss: 4.140673608779907\n",
      "\n",
      "Epoch:    1/10    Loss: 4.475057334899902\n",
      "\n",
      "Epoch:    1/10    Loss: 4.321371917724609\n",
      "\n",
      "Epoch:    1/10    Loss: 4.632921934127808\n",
      "\n",
      "Epoch:    1/10    Loss: 4.312935400009155\n",
      "\n",
      "Epoch:    1/10    Loss: 4.565985670089722\n",
      "\n",
      "Epoch:    1/10    Loss: 4.6986136054992675\n",
      "\n",
      "Epoch:    1/10    Loss: 4.30232681274414\n",
      "\n",
      "Epoch:    1/10    Loss: 4.188272514343262\n",
      "\n",
      "Epoch:    1/10    Loss: 4.125445890426636\n",
      "\n",
      "Epoch:    1/10    Loss: 4.082263784408569\n",
      "\n",
      "Epoch:    1/10    Loss: 4.1279683303833\n",
      "\n",
      "Epoch:    1/10    Loss: 4.200803422927857\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9953166007995606\n",
      "\n",
      "Epoch:    1/10    Loss: 4.1032870006561275\n",
      "\n",
      "Epoch:    1/10    Loss: 4.036396179199219\n",
      "\n",
      "Epoch:    1/10    Loss: 4.319532842636108\n",
      "\n",
      "Epoch:    1/10    Loss: 4.021382560729981\n",
      "\n",
      "Epoch:    1/10    Loss: 4.01417462348938\n",
      "\n",
      "Epoch:    1/10    Loss: 4.382077903747558\n",
      "\n",
      "Epoch:    1/10    Loss: 4.05615493774414\n",
      "\n",
      "Epoch:    1/10    Loss: 4.209038867950439\n",
      "\n",
      "Epoch:    1/10    Loss: 4.364702024459839\n",
      "\n",
      "Epoch:    1/10    Loss: 4.229345779418946\n",
      "\n",
      "Epoch:    1/10    Loss: 4.720839166641236\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9189436721801756\n",
      "\n",
      "Epoch:    1/10    Loss: 3.8053878021240233\n",
      "\n",
      "Epoch:    1/10    Loss: 4.206716032028198\n",
      "\n",
      "Epoch:    1/10    Loss: 4.357396631240845\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4252469444274904\n",
      "\n",
      "Epoch:    1/10    Loss: 4.4398114871978756\n",
      "\n",
      "Epoch:    1/10    Loss: 4.483261575698853\n",
      "\n",
      "Epoch:    1/10    Loss: 4.481898956298828\n",
      "\n",
      "Epoch:    1/10    Loss: 4.174704093933105\n",
      "\n",
      "Epoch:    1/10    Loss: 4.0464323711395265\n",
      "\n",
      "Epoch:    1/10    Loss: 4.402585639953613\n",
      "\n",
      "Epoch:    1/10    Loss: 4.212574672698975\n",
      "\n",
      "Epoch:    1/10    Loss: 4.295338983535767\n",
      "\n",
      "Epoch:    1/10    Loss: 4.185078802108765\n",
      "\n",
      "Epoch:    1/10    Loss: 4.173404417037964\n",
      "\n",
      "Epoch:    1/10    Loss: 4.391754188537598\n",
      "\n",
      "Epoch:    1/10    Loss: 4.145222978591919\n",
      "\n",
      "Epoch:    1/10    Loss: 4.069573802947998\n",
      "\n",
      "Epoch:    1/10    Loss: 4.445033807754516\n",
      "\n",
      "Epoch:    1/10    Loss: 4.415390300750732\n",
      "\n",
      "Epoch:    1/10    Loss: 4.087495489120483\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/10    Loss: 4.230617361068726\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9056504821777343\n",
      "\n",
      "Epoch:    1/10    Loss: 4.103692359924317\n",
      "\n",
      "Epoch:    1/10    Loss: 4.214705171585083\n",
      "\n",
      "Epoch:    1/10    Loss: 4.421868257522583\n",
      "\n",
      "Epoch:    1/10    Loss: 4.150262098312378\n",
      "\n",
      "Epoch:    1/10    Loss: 4.324673147201538\n",
      "\n",
      "Epoch:    1/10    Loss: 4.102217359542847\n",
      "\n",
      "Epoch:    1/10    Loss: 3.992949752807617\n",
      "\n",
      "Epoch:    1/10    Loss: 4.17227689743042\n",
      "\n",
      "Epoch:    1/10    Loss: 4.257792072296143\n",
      "\n",
      "Epoch:    1/10    Loss: 4.260800228118897\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5048912525177\n",
      "\n",
      "Epoch:    1/10    Loss: 4.404163866043091\n",
      "\n",
      "Epoch:    1/10    Loss: 4.331863222122192\n",
      "\n",
      "Epoch:    1/10    Loss: 4.410363082885742\n",
      "\n",
      "Epoch:    1/10    Loss: 4.206347932815552\n",
      "\n",
      "Epoch:    1/10    Loss: 3.936979236602783\n",
      "\n",
      "Epoch:    1/10    Loss: 4.288059682846069\n",
      "\n",
      "Epoch:    1/10    Loss: 4.259829654693603\n",
      "\n",
      "Epoch:    1/10    Loss: 4.224406127929687\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5217545700073245\n",
      "\n",
      "Epoch:    1/10    Loss: 4.344159231185913\n",
      "\n",
      "Epoch:    1/10    Loss: 4.237922973632813\n",
      "\n",
      "Epoch:    1/10    Loss: 4.089349908828735\n",
      "\n",
      "Epoch:    1/10    Loss: 4.232603273391724\n",
      "\n",
      "Epoch:    1/10    Loss: 4.531931295394897\n",
      "\n",
      "Epoch:    1/10    Loss: 4.5956823444366455\n",
      "\n",
      "Epoch:    1/10    Loss: 4.321758537292481\n",
      "\n",
      "Epoch:    1/10    Loss: 4.399394941329956\n",
      "\n",
      "Epoch:    1/10    Loss: 4.444659414291382\n",
      "\n",
      "Epoch:    1/10    Loss: 4.466860027313232\n",
      "\n",
      "Epoch:    1/10    Loss: 4.474651584625244\n",
      "\n",
      "Epoch:    1/10    Loss: 4.533136901855468\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2866370677948\n",
      "\n",
      "Epoch:    1/10    Loss: 4.299268016815185\n",
      "\n",
      "Epoch:    1/10    Loss: 4.15268609046936\n",
      "\n",
      "Epoch:    1/10    Loss: 4.267510461807251\n",
      "\n",
      "Epoch:    1/10    Loss: 4.317281036376953\n",
      "\n",
      "Epoch:    1/10    Loss: 4.422147121429443\n",
      "\n",
      "Epoch:    1/10    Loss: 4.341903896331787\n",
      "\n",
      "Epoch:    1/10    Loss: 4.111362466812134\n",
      "\n",
      "Epoch:    1/10    Loss: 4.491363382339477\n",
      "\n",
      "Epoch:    1/10    Loss: 4.32191759109497\n",
      "\n",
      "Epoch:    1/10    Loss: 4.135092096328735\n",
      "\n",
      "Epoch:    1/10    Loss: 4.430517807006836\n",
      "\n",
      "Epoch:    1/10    Loss: 4.403224639892578\n",
      "\n",
      "Epoch:    1/10    Loss: 4.304523315429687\n",
      "\n",
      "Epoch:    1/10    Loss: 4.434352645874023\n",
      "\n",
      "Epoch:    1/10    Loss: 4.218503551483154\n",
      "\n",
      "Epoch:    1/10    Loss: 4.605445375442505\n",
      "\n",
      "Epoch:    1/10    Loss: 4.296446981430054\n",
      "\n",
      "Epoch:    1/10    Loss: 4.289634370803833\n",
      "\n",
      "Epoch:    1/10    Loss: 4.187830362319946\n",
      "\n",
      "Epoch:    1/10    Loss: 4.500905275344849\n",
      "\n",
      "Epoch:    1/10    Loss: 4.385359477996826\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3445131301879885\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2646076869964595\n",
      "\n",
      "Epoch:    1/10    Loss: 4.16955792427063\n",
      "\n",
      "Epoch:    1/10    Loss: 4.101193523406982\n",
      "\n",
      "Epoch:    1/10    Loss: 4.454387893676758\n",
      "\n",
      "Epoch:    1/10    Loss: 4.616152324676514\n",
      "\n",
      "Epoch:    1/10    Loss: 4.188431711196899\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2010484790802005\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3457128620147705\n",
      "\n",
      "Epoch:    1/10    Loss: 4.188459730148315\n",
      "\n",
      "Epoch:    1/10    Loss: 4.501470041275025\n",
      "\n",
      "Epoch:    1/10    Loss: 4.2914433097839355\n",
      "\n",
      "Epoch:    1/10    Loss: 4.314283285140991\n",
      "\n",
      "Epoch:    1/10    Loss: 4.414880037307739\n",
      "\n",
      "Epoch:    1/10    Loss: 4.523989191055298\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3061583137512205\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9898370456695558\n",
      "\n",
      "Epoch:    1/10    Loss: 4.280315132141113\n",
      "\n",
      "Epoch:    1/10    Loss: 4.251224384307862\n",
      "\n",
      "Epoch:    1/10    Loss: 4.148697824478149\n",
      "\n",
      "Epoch:    1/10    Loss: 4.063576030731201\n",
      "\n",
      "Epoch:    1/10    Loss: 4.245180835723877\n",
      "\n",
      "Epoch:    1/10    Loss: 4.491369886398315\n",
      "\n",
      "Epoch:    1/10    Loss: 4.420568685531617\n",
      "\n",
      "Epoch:    1/10    Loss: 4.3568319320678714\n",
      "\n",
      "Epoch:    1/10    Loss: 4.288676080703735\n",
      "\n",
      "Epoch:    1/10    Loss: 4.162770919799804\n",
      "\n",
      "Epoch:    1/10    Loss: 3.9851510620117185\n",
      "\n",
      "Epoch:    1/10    Loss: 4.191088094711303\n",
      "\n",
      "Epoch:    1/10    Loss: 4.151468868255615\n",
      "\n",
      "Epoch:    1/10    Loss: 4.158517074584961\n",
      "\n",
      "Epoch:    1/10    Loss: 5.160737171173095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n",
      "Epoch:    2/10    Loss: 4.4743899689164275\n",
      "\n",
      "Epoch:    2/10    Loss: 4.137075719833374\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8318759632110595\n",
      "\n",
      "Epoch:    2/10    Loss: 4.120935125350952\n",
      "\n",
      "Epoch:    2/10    Loss: 3.851857290267944\n",
      "\n",
      "Epoch:    2/10    Loss: 3.866565885543823\n",
      "\n",
      "Epoch:    2/10    Loss: 4.041164169311523\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9318419170379637\n",
      "\n",
      "Epoch:    2/10    Loss: 4.054263525009155\n",
      "\n",
      "Epoch:    2/10    Loss: 3.844706163406372\n",
      "\n",
      "Epoch:    2/10    Loss: 4.099021558761597\n",
      "\n",
      "Epoch:    2/10    Loss: 3.950495195388794\n",
      "\n",
      "Epoch:    2/10    Loss: 4.03415813446045\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7052436447143555\n",
      "\n",
      "Epoch:    2/10    Loss: 4.054402408599853\n",
      "\n",
      "Epoch:    2/10    Loss: 4.061418142318725\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7217216014862062\n",
      "\n",
      "Epoch:    2/10    Loss: 4.090556306838989\n",
      "\n",
      "Epoch:    2/10    Loss: 4.026103382110596\n",
      "\n",
      "Epoch:    2/10    Loss: 4.146270198822021\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8799396324157716\n",
      "\n",
      "Epoch:    2/10    Loss: 3.954551305770874\n",
      "\n",
      "Epoch:    2/10    Loss: 4.109362106323243\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9827867984771728\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9668034076690675\n",
      "\n",
      "Epoch:    2/10    Loss: 4.251064996719361\n",
      "\n",
      "Epoch:    2/10    Loss: 3.852586154937744\n",
      "\n",
      "Epoch:    2/10    Loss: 4.168140144348144\n",
      "\n",
      "Epoch:    2/10    Loss: 3.976699571609497\n",
      "\n",
      "Epoch:    2/10    Loss: 3.712699155807495\n",
      "\n",
      "Epoch:    2/10    Loss: 4.151139516830444\n",
      "\n",
      "Epoch:    2/10    Loss: 3.897592706680298\n",
      "\n",
      "Epoch:    2/10    Loss: 4.421016092300415\n",
      "\n",
      "Epoch:    2/10    Loss: 4.206060590744019\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9203007411956787\n",
      "\n",
      "Epoch:    2/10    Loss: 3.797632923126221\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7359074401855468\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7271809864044187\n",
      "\n",
      "Epoch:    2/10    Loss: 3.830787353515625\n",
      "\n",
      "Epoch:    2/10    Loss: 3.888891649246216\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6273441886901856\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8051044368743896\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9852681064605715\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9320952987670896\n",
      "\n",
      "Epoch:    2/10    Loss: 4.420896348953247\n",
      "\n",
      "Epoch:    2/10    Loss: 4.052102146148681\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8703981494903563\n",
      "\n",
      "Epoch:    2/10    Loss: 4.019300289154053\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6010681056976317\n",
      "\n",
      "Epoch:    2/10    Loss: 3.908264846801758\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9398188686370847\n",
      "\n",
      "Epoch:    2/10    Loss: 3.911156120300293\n",
      "\n",
      "Epoch:    2/10    Loss: 3.995581531524658\n",
      "\n",
      "Epoch:    2/10    Loss: 3.912236614227295\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8959936809539797\n",
      "\n",
      "Epoch:    2/10    Loss: 3.842577362060547\n",
      "\n",
      "Epoch:    2/10    Loss: 3.686413049697876\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6267660999298097\n",
      "\n",
      "Epoch:    2/10    Loss: 3.63457989692688\n",
      "\n",
      "Epoch:    2/10    Loss: 3.775275259017944\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9653366661071776\n",
      "\n",
      "Epoch:    2/10    Loss: 4.027816066741943\n",
      "\n",
      "Epoch:    2/10    Loss: 3.917748384475708\n",
      "\n",
      "Epoch:    2/10    Loss: 3.577261209487915\n",
      "\n",
      "Epoch:    2/10    Loss: 3.705039176940918\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7416588497161865\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6981387901306153\n",
      "\n",
      "Epoch:    2/10    Loss: 3.96109356880188\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6568459987640383\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7225604820251466\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8428421020507812\n",
      "\n",
      "Epoch:    2/10    Loss: 3.866111660003662\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7883676528930663\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9065032958984376\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8164944553375246\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7069058132171633\n",
      "\n",
      "Epoch:    2/10    Loss: 4.008555974960327\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7202313804626463\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7360464191436766\n",
      "\n",
      "Epoch:    2/10    Loss: 4.22305118560791\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7423707580566408\n",
      "\n",
      "Epoch:    2/10    Loss: 4.405206165313721\n",
      "\n",
      "Epoch:    2/10    Loss: 4.167329874038696\n",
      "\n",
      "Epoch:    2/10    Loss: 3.803863592147827\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7815528964996337\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7473323917388917\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9988312911987305\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1893556118011475\n",
      "\n",
      "Epoch:    2/10    Loss: 4.02330756187439\n",
      "\n",
      "Epoch:    2/10    Loss: 3.718281478881836\n",
      "\n",
      "Epoch:    2/10    Loss: 4.010679483413696\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8483052921295164\n",
      "\n",
      "Epoch:    2/10    Loss: 3.890656280517578\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7665767574310305\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8584024715423584\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8729476261138918\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8321782779693603\n",
      "\n",
      "Epoch:    2/10    Loss: 3.985277738571167\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6105748271942137\n",
      "\n",
      "Epoch:    2/10    Loss: 3.692540168762207\n",
      "\n",
      "Epoch:    2/10    Loss: 4.001092453002929\n",
      "\n",
      "Epoch:    2/10    Loss: 3.810204362869263\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8312722873687743\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8307336711883546\n",
      "\n",
      "Epoch:    2/10    Loss: 4.192769117355347\n",
      "\n",
      "Epoch:    2/10    Loss: 4.29931077003479\n",
      "\n",
      "Epoch:    2/10    Loss: 4.062319927215576\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8267901229858396\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7306641864776613\n",
      "\n",
      "Epoch:    2/10    Loss: 4.018551197052002\n",
      "\n",
      "Epoch:    2/10    Loss: 3.963651990890503\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9281646060943602\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8704378986358643\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9387942123413087\n",
      "\n",
      "Epoch:    2/10    Loss: 4.09143816947937\n",
      "\n",
      "Epoch:    2/10    Loss: 4.029397172927856\n",
      "\n",
      "Epoch:    2/10    Loss: 4.077073726654053\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8908926391601564\n",
      "\n",
      "Epoch:    2/10    Loss: 4.121434497833252\n",
      "\n",
      "Epoch:    2/10    Loss: 4.1248244953155515\n",
      "\n",
      "Epoch:    2/10    Loss: 4.034227905273437\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8761769676208497\n",
      "\n",
      "Epoch:    2/10    Loss: 4.062356224060059\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9193894481658935\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8041033363342285\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6302109146118164\n",
      "\n",
      "Epoch:    2/10    Loss: 4.025756597518921\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9319486236572265\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9185868072509766\n",
      "\n",
      "Epoch:    2/10    Loss: 4.004614763259887\n",
      "\n",
      "Epoch:    2/10    Loss: 4.096997680664063\n",
      "\n",
      "Epoch:    2/10    Loss: 3.755163984298706\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9602904891967774\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8888726329803465\n",
      "\n",
      "Epoch:    2/10    Loss: 3.977015733718872\n",
      "\n",
      "Epoch:    2/10    Loss: 3.830152978897095\n",
      "\n",
      "Epoch:    2/10    Loss: 3.85676926612854\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9017312335968017\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8870255088806154\n",
      "\n",
      "Epoch:    2/10    Loss: 3.771856594085693\n",
      "\n",
      "Epoch:    2/10    Loss: 3.744126281738281\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7164055728912353\n",
      "\n",
      "Epoch:    2/10    Loss: 3.825452766418457\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9673287582397463\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6605672359466555\n",
      "\n",
      "Epoch:    2/10    Loss: 3.987448205947876\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8012409591674805\n",
      "\n",
      "Epoch:    2/10    Loss: 4.153344345092774\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8260120964050293\n",
      "\n",
      "Epoch:    2/10    Loss: 4.110187559127808\n",
      "\n",
      "Epoch:    2/10    Loss: 4.2016223049163814\n",
      "\n",
      "Epoch:    2/10    Loss: 3.894662256240845\n",
      "\n",
      "Epoch:    2/10    Loss: 3.721841421127319\n",
      "\n",
      "Epoch:    2/10    Loss: 3.703682737350464\n",
      "\n",
      "Epoch:    2/10    Loss: 3.680287923812866\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7580137348175047\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8097416973114013\n",
      "\n",
      "Epoch:    2/10    Loss: 3.570164384841919\n",
      "\n",
      "Epoch:    2/10    Loss: 3.699566583633423\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6440637588500975\n",
      "\n",
      "Epoch:    2/10    Loss: 3.868215284347534\n",
      "\n",
      "Epoch:    2/10    Loss: 3.607239770889282\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7115157890319823\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9647121906280516\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6479692363739016\n",
      "\n",
      "Epoch:    2/10    Loss: 3.783805503845215\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9436867523193357\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8426824188232422\n",
      "\n",
      "Epoch:    2/10    Loss: 4.305247859954834\n",
      "\n",
      "Epoch:    2/10    Loss: 3.55362286567688\n",
      "\n",
      "Epoch:    2/10    Loss: 3.4616924953460693\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8300167655944826\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8491486740112304\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9280737686157225\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0276218700408934\n",
      "\n",
      "Epoch:    2/10    Loss: 4.03727783203125\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8948480129241942\n",
      "\n",
      "Epoch:    2/10    Loss: 3.698351583480835\n",
      "\n",
      "Epoch:    2/10    Loss: 3.61515435218811\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9622550201416016\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8210317516326904\n",
      "\n",
      "Epoch:    2/10    Loss: 3.912040796279907\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8029837608337402\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7241147422790526\n",
      "\n",
      "Epoch:    2/10    Loss: 3.911979274749756\n",
      "\n",
      "Epoch:    2/10    Loss: 3.731615447998047\n",
      "\n",
      "Epoch:    2/10    Loss: 3.685207166671753\n",
      "\n",
      "Epoch:    2/10    Loss: 3.972346429824829\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9757253170013427\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    2/10    Loss: 3.726663017272949\n",
      "\n",
      "Epoch:    2/10    Loss: 3.835032625198364\n",
      "\n",
      "Epoch:    2/10    Loss: 3.470537347793579\n",
      "\n",
      "Epoch:    2/10    Loss: 3.694989252090454\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8016589069366455\n",
      "\n",
      "Epoch:    2/10    Loss: 4.018163890838623\n",
      "\n",
      "Epoch:    2/10    Loss: 3.774096841812134\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9162925815582277\n",
      "\n",
      "Epoch:    2/10    Loss: 3.68971284866333\n",
      "\n",
      "Epoch:    2/10    Loss: 3.5245525646209717\n",
      "\n",
      "Epoch:    2/10    Loss: 3.794970817565918\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8648329734802247\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8787668132781983\n",
      "\n",
      "Epoch:    2/10    Loss: 4.068665170669556\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9782222652435304\n",
      "\n",
      "Epoch:    2/10    Loss: 3.928909034729004\n",
      "\n",
      "Epoch:    2/10    Loss: 4.006608371734619\n",
      "\n",
      "Epoch:    2/10    Loss: 3.909468870162964\n",
      "\n",
      "Epoch:    2/10    Loss: 3.6532833576202393\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8845678997039794\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8797965621948243\n",
      "\n",
      "Epoch:    2/10    Loss: 3.85100923538208\n",
      "\n",
      "Epoch:    2/10    Loss: 4.137432708740234\n",
      "\n",
      "Epoch:    2/10    Loss: 3.933188695907593\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8739368152618407\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7294875144958497\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8706497383117675\n",
      "\n",
      "Epoch:    2/10    Loss: 4.094647645950317\n",
      "\n",
      "Epoch:    2/10    Loss: 4.072591667175293\n",
      "\n",
      "Epoch:    2/10    Loss: 3.83031418800354\n",
      "\n",
      "Epoch:    2/10    Loss: 3.989032258987427\n",
      "\n",
      "Epoch:    2/10    Loss: 4.001799325942994\n",
      "\n",
      "Epoch:    2/10    Loss: 4.09677264213562\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0628606224060055\n",
      "\n",
      "Epoch:    2/10    Loss: 4.103021602630616\n",
      "\n",
      "Epoch:    2/10    Loss: 3.901991672515869\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9166557598114013\n",
      "\n",
      "Epoch:    2/10    Loss: 3.81397891998291\n",
      "\n",
      "Epoch:    2/10    Loss: 3.855200242996216\n",
      "\n",
      "Epoch:    2/10    Loss: 3.904654483795166\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0650090408325195\n",
      "\n",
      "Epoch:    2/10    Loss: 3.968411750793457\n",
      "\n",
      "Epoch:    2/10    Loss: 3.777329111099243\n",
      "\n",
      "Epoch:    2/10    Loss: 4.120129671096802\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9583356857299803\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7493767738342285\n",
      "\n",
      "Epoch:    2/10    Loss: 3.979824047088623\n",
      "\n",
      "Epoch:    2/10    Loss: 3.944010028839111\n",
      "\n",
      "Epoch:    2/10    Loss: 3.78091947555542\n",
      "\n",
      "Epoch:    2/10    Loss: 4.000009021759033\n",
      "\n",
      "Epoch:    2/10    Loss: 3.828593416213989\n",
      "\n",
      "Epoch:    2/10    Loss: 4.150865573883056\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8717844104766845\n",
      "\n",
      "Epoch:    2/10    Loss: 3.845470457077026\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8292614459991454\n",
      "\n",
      "Epoch:    2/10    Loss: 4.037397499084473\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9394753646850584\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9789426612854\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9095980167388915\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8204081058502197\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7723545742034914\n",
      "\n",
      "Epoch:    2/10    Loss: 4.028822860717773\n",
      "\n",
      "Epoch:    2/10    Loss: 4.202384033203125\n",
      "\n",
      "Epoch:    2/10    Loss: 3.837150144577026\n",
      "\n",
      "Epoch:    2/10    Loss: 3.800817413330078\n",
      "\n",
      "Epoch:    2/10    Loss: 3.863916988372803\n",
      "\n",
      "Epoch:    2/10    Loss: 3.739554615020752\n",
      "\n",
      "Epoch:    2/10    Loss: 4.106536874771118\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8932804584503176\n",
      "\n",
      "Epoch:    2/10    Loss: 3.880718460083008\n",
      "\n",
      "Epoch:    2/10    Loss: 3.952520389556885\n",
      "\n",
      "Epoch:    2/10    Loss: 4.0499683856964115\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8458227729797363\n",
      "\n",
      "Epoch:    2/10    Loss: 3.676622724533081\n",
      "\n",
      "Epoch:    2/10    Loss: 3.985614051818848\n",
      "\n",
      "Epoch:    2/10    Loss: 3.92323525428772\n",
      "\n",
      "Epoch:    2/10    Loss: 3.8028996753692628\n",
      "\n",
      "Epoch:    2/10    Loss: 3.67250883102417\n",
      "\n",
      "Epoch:    2/10    Loss: 3.84363338470459\n",
      "\n",
      "Epoch:    2/10    Loss: 4.112682800292969\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9924797439575195\n",
      "\n",
      "Epoch:    2/10    Loss: 3.9494777584075926\n",
      "\n",
      "Epoch:    2/10    Loss: 3.874587268829346\n",
      "\n",
      "Epoch:    2/10    Loss: 3.753020944595337\n",
      "\n",
      "Epoch:    2/10    Loss: 3.539477376937866\n",
      "\n",
      "Epoch:    2/10    Loss: 3.853740482330322\n",
      "\n",
      "Epoch:    2/10    Loss: 3.7603162574768065\n",
      "\n",
      "Epoch:    2/10    Loss: 3.841439514160156\n",
      "\n",
      "Epoch:    2/10    Loss: 4.529317493438721\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    3/10    Loss: 4.128840729247692\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9005224895477295\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5054914569854736\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8598651695251465\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5975613403320312\n",
      "\n",
      "Epoch:    3/10    Loss: 3.613552436828613\n",
      "\n",
      "Epoch:    3/10    Loss: 3.778157138824463\n",
      "\n",
      "Epoch:    3/10    Loss: 3.621805763244629\n",
      "\n",
      "Epoch:    3/10    Loss: 3.800868339538574\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6177034091949465\n",
      "\n",
      "Epoch:    3/10    Loss: 3.855401496887207\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6851695823669433\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7740636539459227\n",
      "\n",
      "Epoch:    3/10    Loss: 3.509511260986328\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6939006805419923\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7958355712890626\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4956201934814453\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8474432945251467\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7815671348571778\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8020033645629883\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5807168006896974\n",
      "\n",
      "Epoch:    3/10    Loss: 3.673777389526367\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8875368881225585\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7883601284027097\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7671768379211428\n",
      "\n",
      "Epoch:    3/10    Loss: 3.969176836013794\n",
      "\n",
      "Epoch:    3/10    Loss: 3.61574275970459\n",
      "\n",
      "Epoch:    3/10    Loss: 3.915055103302002\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7623699474334718\n",
      "\n",
      "Epoch:    3/10    Loss: 3.490088310241699\n",
      "\n",
      "Epoch:    3/10    Loss: 3.899491424560547\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6433342361450194\n",
      "\n",
      "Epoch:    3/10    Loss: 4.177862329483032\n",
      "\n",
      "Epoch:    3/10    Loss: 3.928536891937256\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6788899803161623\n",
      "\n",
      "Epoch:    3/10    Loss: 3.591468334197998\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4871572780609132\n",
      "\n",
      "Epoch:    3/10    Loss: 3.514660053253174\n",
      "\n",
      "Epoch:    3/10    Loss: 3.618629550933838\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6845721626281738\n",
      "\n",
      "Epoch:    3/10    Loss: 3.43896764755249\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5475243759155273\n",
      "\n",
      "Epoch:    3/10    Loss: 3.723511257171631\n",
      "\n",
      "Epoch:    3/10    Loss: 3.675178356170654\n",
      "\n",
      "Epoch:    3/10    Loss: 4.187500085830688\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7621857357025146\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6195050430297853\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7654022789001464\n",
      "\n",
      "Epoch:    3/10    Loss: 3.430550937652588\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7148833084106445\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7690109634399414\n",
      "\n",
      "Epoch:    3/10    Loss: 3.683278579711914\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7538224124908446\n",
      "\n",
      "Epoch:    3/10    Loss: 3.661691541671753\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6612781143188475\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5696771812438963\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4735961151123047\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4496250629425047\n",
      "\n",
      "Epoch:    3/10    Loss: 3.41227409362793\n",
      "\n",
      "Epoch:    3/10    Loss: 3.547970705032349\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7074657249450684\n",
      "\n",
      "Epoch:    3/10    Loss: 3.765728483200073\n",
      "\n",
      "Epoch:    3/10    Loss: 3.724547166824341\n",
      "\n",
      "Epoch:    3/10    Loss: 3.3810871505737303\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4751306056976317\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5753804779052736\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4641072368621826\n",
      "\n",
      "Epoch:    3/10    Loss: 3.693149137496948\n",
      "\n",
      "Epoch:    3/10    Loss: 3.436568374633789\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5019115352630616\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5955185985565183\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6329975509643555\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5802979946136473\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6324333000183104\n",
      "\n",
      "Epoch:    3/10    Loss: 3.576734104156494\n",
      "\n",
      "Epoch:    3/10    Loss: 3.465384073257446\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7519230461120605\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4913450717926025\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5242371940612793\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9475138664245604\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5587846279144286\n",
      "\n",
      "Epoch:    3/10    Loss: 4.099117116928101\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8926297760009767\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6199193000793457\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5851369380950926\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5451020336151124\n",
      "\n",
      "Epoch:    3/10    Loss: 3.657114152908325\n",
      "\n",
      "Epoch:    3/10    Loss: 3.862400007247925\n",
      "\n",
      "Epoch:    3/10    Loss: 3.692277488708496\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4987541580200197\n",
      "\n",
      "Epoch:    3/10    Loss: 3.72298677444458\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6092308712005616\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6549253559112547\n",
      "\n",
      "Epoch:    3/10    Loss: 3.527530145645142\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6378197193145754\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6106925868988036\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5863473320007326\n",
      "\n",
      "Epoch:    3/10    Loss: 3.778275489807129\n",
      "\n",
      "Epoch:    3/10    Loss: 3.421036024093628\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4930677032470703\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    3/10    Loss: 3.7837017822265624\n",
      "\n",
      "Epoch:    3/10    Loss: 3.654238014221191\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6321446800231936\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6131166362762452\n",
      "\n",
      "Epoch:    3/10    Loss: 3.934312982559204\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9929676628112794\n",
      "\n",
      "Epoch:    3/10    Loss: 3.816590280532837\n",
      "\n",
      "Epoch:    3/10    Loss: 3.624967908859253\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4979167938232423\n",
      "\n",
      "Epoch:    3/10    Loss: 3.720128402709961\n",
      "\n",
      "Epoch:    3/10    Loss: 3.692250566482544\n",
      "\n",
      "Epoch:    3/10    Loss: 3.646760034561157\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6376095104217527\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7053057670593263\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8826655960083007\n",
      "\n",
      "Epoch:    3/10    Loss: 3.769858732223511\n",
      "\n",
      "Epoch:    3/10    Loss: 3.841695098876953\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6917675495147706\n",
      "\n",
      "Epoch:    3/10    Loss: 3.916826992034912\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8834178829193116\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8133374309539794\n",
      "\n",
      "Epoch:    3/10    Loss: 3.661955461502075\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8219008159637453\n",
      "\n",
      "Epoch:    3/10    Loss: 3.693577194213867\n",
      "\n",
      "Epoch:    3/10    Loss: 3.578751802444458\n",
      "\n",
      "Epoch:    3/10    Loss: 3.3556730461120607\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7856152629852295\n",
      "\n",
      "Epoch:    3/10    Loss: 3.714667167663574\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7060230445861815\n",
      "\n",
      "Epoch:    3/10    Loss: 3.744235372543335\n",
      "\n",
      "Epoch:    3/10    Loss: 3.845383815765381\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5337469673156736\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7056756114959715\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6514171028137206\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7231432437896728\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5645729160308837\n",
      "\n",
      "Epoch:    3/10    Loss: 3.60563627243042\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6575929164886474\n",
      "\n",
      "Epoch:    3/10    Loss: 3.60758282661438\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5194428634643553\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5270020008087157\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5130248165130613\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5129644584655764\n",
      "\n",
      "Epoch:    3/10    Loss: 3.713358287811279\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4130422401428224\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7071700286865235\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4845861053466796\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8697877311706543\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5665044593811035\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8151690578460693\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9172186851501465\n",
      "\n",
      "Epoch:    3/10    Loss: 3.676964168548584\n",
      "\n",
      "Epoch:    3/10    Loss: 3.560803279876709\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5164067459106447\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4778044700622557\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5422684574127197\n",
      "\n",
      "Epoch:    3/10    Loss: 3.589670391082764\n",
      "\n",
      "Epoch:    3/10    Loss: 3.3562502002716066\n",
      "\n",
      "Epoch:    3/10    Loss: 3.519261875152588\n",
      "\n",
      "Epoch:    3/10    Loss: 3.462106533050537\n",
      "\n",
      "Epoch:    3/10    Loss: 3.500596218109131\n",
      "\n",
      "Epoch:    3/10    Loss: 3.2903212261199952\n",
      "\n",
      "Epoch:    3/10    Loss: 3.479510564804077\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7414625453948975\n",
      "\n",
      "Epoch:    3/10    Loss: 3.471650323867798\n",
      "\n",
      "Epoch:    3/10    Loss: 3.577534580230713\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7220944690704347\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5396952629089355\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9699306869506836\n",
      "\n",
      "Epoch:    3/10    Loss: 3.3326028060913084\n",
      "\n",
      "Epoch:    3/10    Loss: 3.2619979763031006\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6193789768218996\n",
      "\n",
      "Epoch:    3/10    Loss: 3.60134596824646\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6802921295166016\n",
      "\n",
      "Epoch:    3/10    Loss: 3.851813135147095\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7863634967803956\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5544645309448244\n",
      "\n",
      "Epoch:    3/10    Loss: 3.491897621154785\n",
      "\n",
      "Epoch:    3/10    Loss: 3.3885455989837645\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7625143146514892\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5943200302124025\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7227285289764405\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5903526878356935\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5233280944824217\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6772923564910887\n",
      "\n",
      "Epoch:    3/10    Loss: 3.487467565536499\n",
      "\n",
      "Epoch:    3/10    Loss: 3.447211380004883\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6933863162994385\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7423877620697024\n",
      "\n",
      "Epoch:    3/10    Loss: 3.498626880645752\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6334314155578613\n",
      "\n",
      "Epoch:    3/10    Loss: 3.2619011974334717\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4725664043426514\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5613781070709227\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7790524196624755\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5306507205963134\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6378664684295656\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4407414531707765\n",
      "\n",
      "Epoch:    3/10    Loss: 3.346839017868042\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6088658714294435\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6548310470581056\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6451466560363768\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8184287929534912\n",
      "\n",
      "Epoch:    3/10    Loss: 3.762289352416992\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7122979164123535\n",
      "\n",
      "Epoch:    3/10    Loss: 3.797151460647583\n",
      "\n",
      "Epoch:    3/10    Loss: 3.717952165603638\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4543923473358156\n",
      "\n",
      "Epoch:    3/10    Loss: 3.653893594741821\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6466275215148927\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6138474559783935\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8723333740234374\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7057694149017335\n",
      "\n",
      "Epoch:    3/10    Loss: 3.699809455871582\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5065072441101073\n",
      "\n",
      "Epoch:    3/10    Loss: 3.656871213912964\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8774900913238524\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7988253593444825\n",
      "\n",
      "Epoch:    3/10    Loss: 3.564766969680786\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7703889274597167\n",
      "\n",
      "Epoch:    3/10    Loss: 3.782584400177002\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8744145393371583\n",
      "\n",
      "Epoch:    3/10    Loss: 3.78375075340271\n",
      "\n",
      "Epoch:    3/10    Loss: 3.837333583831787\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6433069610595705\n",
      "\n",
      "Epoch:    3/10    Loss: 3.643174810409546\n",
      "\n",
      "Epoch:    3/10    Loss: 3.641057777404785\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6585668182373046\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7047237491607667\n",
      "\n",
      "Epoch:    3/10    Loss: 3.830792646408081\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7757012176513673\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5886448001861573\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8731747245788575\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6966080474853515\n",
      "\n",
      "Epoch:    3/10    Loss: 3.543507022857666\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7460873889923096\n",
      "\n",
      "Epoch:    3/10    Loss: 3.710663175582886\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5203642654418945\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7920254993438722\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6174376583099366\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8787405109405517\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6423795890808104\n",
      "\n",
      "Epoch:    3/10    Loss: 3.633324508666992\n",
      "\n",
      "Epoch:    3/10    Loss: 3.629072551727295\n",
      "\n",
      "Epoch:    3/10    Loss: 3.786669340133667\n",
      "\n",
      "Epoch:    3/10    Loss: 3.685900192260742\n",
      "\n",
      "Epoch:    3/10    Loss: 3.758591527938843\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6837804031372072\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5847145462036134\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5975993633270265\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8108112239837646\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9723576354980468\n",
      "\n",
      "Epoch:    3/10    Loss: 3.658723039627075\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6081990242004394\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6107202053070067\n",
      "\n",
      "Epoch:    3/10    Loss: 3.518269567489624\n",
      "\n",
      "Epoch:    3/10    Loss: 3.9125132083892824\n",
      "\n",
      "Epoch:    3/10    Loss: 3.668990201950073\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6281911373138427\n",
      "\n",
      "Epoch:    3/10    Loss: 3.705394105911255\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7507050037384033\n",
      "\n",
      "Epoch:    3/10    Loss: 3.648848752975464\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4641096496582033\n",
      "\n",
      "Epoch:    3/10    Loss: 3.819957618713379\n",
      "\n",
      "Epoch:    3/10    Loss: 3.7045497703552246\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5875846672058107\n",
      "\n",
      "Epoch:    3/10    Loss: 3.464131736755371\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5772649478912353\n",
      "\n",
      "Epoch:    3/10    Loss: 3.8549206352233885\n",
      "\n",
      "Epoch:    3/10    Loss: 3.775525522232056\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6888097286224366\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6423119831085207\n",
      "\n",
      "Epoch:    3/10    Loss: 3.512522802352905\n",
      "\n",
      "Epoch:    3/10    Loss: 3.4164302921295167\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6558925533294677\n",
      "\n",
      "Epoch:    3/10    Loss: 3.5349148750305175\n",
      "\n",
      "Epoch:    3/10    Loss: 3.6018151092529296\n",
      "\n",
      "Epoch:    3/10    Loss: 4.133912353515625\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    4/10    Loss: 7.275369389112606\n",
      "\n",
      "Epoch:    4/10    Loss: 3.685929479598999\n",
      "\n",
      "Epoch:    4/10    Loss: 3.307509813308716\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6693273830413817\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4599953937530517\n",
      "\n",
      "Epoch:    4/10    Loss: 3.479819040298462\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6216814708709717\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4147021770477295\n",
      "\n",
      "Epoch:    4/10    Loss: 3.648005933761597\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4667351627349854\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    4/10    Loss: 3.645128707885742\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4706784152984618\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5725491046905518\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3501365280151365\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5462893581390382\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6470698070526124\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3505713176727294\n",
      "\n",
      "Epoch:    4/10    Loss: 3.65685453414917\n",
      "\n",
      "Epoch:    4/10    Loss: 3.574309730529785\n",
      "\n",
      "Epoch:    4/10    Loss: 3.577864179611206\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3977624702453615\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5350167846679685\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6591735649108887\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6201537036895752\n",
      "\n",
      "Epoch:    4/10    Loss: 3.584548873901367\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7839930343627928\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4451833248138426\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6941200160980223\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5920093631744385\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3410742473602295\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7002592372894285\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4600292682647704\n",
      "\n",
      "Epoch:    4/10    Loss: 3.979908208847046\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7293669605255126\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4998427295684813\n",
      "\n",
      "Epoch:    4/10    Loss: 3.364966688156128\n",
      "\n",
      "Epoch:    4/10    Loss: 3.322688636779785\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3430949306488036\n",
      "\n",
      "Epoch:    4/10    Loss: 3.461991024017334\n",
      "\n",
      "Epoch:    4/10    Loss: 3.509309892654419\n",
      "\n",
      "Epoch:    4/10    Loss: 3.264738712310791\n",
      "\n",
      "Epoch:    4/10    Loss: 3.348014917373657\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5514664363861086\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5258245849609375\n",
      "\n",
      "Epoch:    4/10    Loss: 3.9376894664764404\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6211789321899412\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4371062183380126\n",
      "\n",
      "Epoch:    4/10    Loss: 3.572664670944214\n",
      "\n",
      "Epoch:    4/10    Loss: 3.2519103717803954\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5426738166809084\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5776611614227294\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5520253562927246\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5692375183105467\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4687716960906982\n",
      "\n",
      "Epoch:    4/10    Loss: 3.488945789337158\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3881209468841553\n",
      "\n",
      "Epoch:    4/10    Loss: 3.313558416366577\n",
      "\n",
      "Epoch:    4/10    Loss: 3.273666114807129\n",
      "\n",
      "Epoch:    4/10    Loss: 3.264938373565674\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3535864639282225\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4756775665283204\n",
      "\n",
      "Epoch:    4/10    Loss: 3.509854726791382\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5250255489349365\n",
      "\n",
      "Epoch:    4/10    Loss: 3.183060464859009\n",
      "\n",
      "Epoch:    4/10    Loss: 3.322354555130005\n",
      "\n",
      "Epoch:    4/10    Loss: 3.363347120285034\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3300690937042234\n",
      "\n",
      "Epoch:    4/10    Loss: 3.516884489059448\n",
      "\n",
      "Epoch:    4/10    Loss: 3.272085943222046\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3565224742889406\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4300847244262695\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4297662448883055\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4437622261047363\n",
      "\n",
      "Epoch:    4/10    Loss: 3.518921308517456\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4307648372650146\n",
      "\n",
      "Epoch:    4/10    Loss: 3.334698209762573\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5915000343322756\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3221942138671876\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3537454986572266\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7652361392974854\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3899729442596436\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8463219738006593\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6771161937713623\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4296748542785647\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4496452617645263\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3559393215179445\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4598950576782226\n",
      "\n",
      "Epoch:    4/10    Loss: 3.649521942138672\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4559281730651854\n",
      "\n",
      "Epoch:    4/10    Loss: 3.309262275695801\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5353955268859862\n",
      "\n",
      "Epoch:    4/10    Loss: 3.413278675079346\n",
      "\n",
      "Epoch:    4/10    Loss: 3.457212038040161\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3901991271972656\n",
      "\n",
      "Epoch:    4/10    Loss: 3.446908893585205\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3939412593841554\n",
      "\n",
      "Epoch:    4/10    Loss: 3.42079439163208\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5810930824279783\n",
      "\n",
      "Epoch:    4/10    Loss: 3.271933879852295\n",
      "\n",
      "Epoch:    4/10    Loss: 3.358553991317749\n",
      "\n",
      "Epoch:    4/10    Loss: 3.647909860610962\n",
      "\n",
      "Epoch:    4/10    Loss: 3.448853988647461\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4475048065185545\n",
      "\n",
      "Epoch:    4/10    Loss: 3.442963275909424\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7413816261291504\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8262636470794678\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6410211753845214\n",
      "\n",
      "Epoch:    4/10    Loss: 3.457113924026489\n",
      "\n",
      "Epoch:    4/10    Loss: 3.318740653991699\n",
      "\n",
      "Epoch:    4/10    Loss: 3.508173666000366\n",
      "\n",
      "Epoch:    4/10    Loss: 3.512891550064087\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4533451271057127\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4349903297424316\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4874453926086426\n",
      "\n",
      "Epoch:    4/10    Loss: 3.622328042984009\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5706599807739257\n",
      "\n",
      "Epoch:    4/10    Loss: 3.656968698501587\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4757111167907713\n",
      "\n",
      "Epoch:    4/10    Loss: 3.726183090209961\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6883967113494873\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6557834148406982\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4894837379455566\n",
      "\n",
      "Epoch:    4/10    Loss: 3.616051664352417\n",
      "\n",
      "Epoch:    4/10    Loss: 3.514813642501831\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4207913970947263\n",
      "\n",
      "Epoch:    4/10    Loss: 3.2235876941680908\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5985159492492675\n",
      "\n",
      "Epoch:    4/10    Loss: 3.530260419845581\n",
      "\n",
      "Epoch:    4/10    Loss: 3.518190460205078\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4874779319763185\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6017526817321777\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4014475631713865\n",
      "\n",
      "Epoch:    4/10    Loss: 3.538880777359009\n",
      "\n",
      "Epoch:    4/10    Loss: 3.486256313323975\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5344153785705568\n",
      "\n",
      "Epoch:    4/10    Loss: 3.359174327850342\n",
      "\n",
      "Epoch:    4/10    Loss: 3.370423879623413\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4896170806884768\n",
      "\n",
      "Epoch:    4/10    Loss: 3.436993570327759\n",
      "\n",
      "Epoch:    4/10    Loss: 3.31177321434021\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3555347156524657\n",
      "\n",
      "Epoch:    4/10    Loss: 3.316972017288208\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3342822265625\n",
      "\n",
      "Epoch:    4/10    Loss: 3.519691114425659\n",
      "\n",
      "Epoch:    4/10    Loss: 3.2760400199890136\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4725316905975343\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3272562503814695\n",
      "\n",
      "Epoch:    4/10    Loss: 3.661301441192627\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3909199333190916\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6323333263397215\n",
      "\n",
      "Epoch:    4/10    Loss: 3.74986270904541\n",
      "\n",
      "Epoch:    4/10    Loss: 3.485892724990845\n",
      "\n",
      "Epoch:    4/10    Loss: 3.384146041870117\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3505222034454345\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3778941345214846\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4124040508270266\n",
      "\n",
      "Epoch:    4/10    Loss: 3.433976716995239\n",
      "\n",
      "Epoch:    4/10    Loss: 3.1988710880279543\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3706761741638185\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3208855819702148\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3861577796936033\n",
      "\n",
      "Epoch:    4/10    Loss: 3.1596382999420167\n",
      "\n",
      "Epoch:    4/10    Loss: 3.323425922393799\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5366541862487795\n",
      "\n",
      "Epoch:    4/10    Loss: 3.2821616172790526\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4175825023651125\n",
      "\n",
      "Epoch:    4/10    Loss: 3.514975833892822\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3728411483764646\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6952834701538086\n",
      "\n",
      "Epoch:    4/10    Loss: 3.1989630603790284\n",
      "\n",
      "Epoch:    4/10    Loss: 3.159551820755005\n",
      "\n",
      "Epoch:    4/10    Loss: 3.462340898513794\n",
      "\n",
      "Epoch:    4/10    Loss: 3.407387237548828\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4835594272613526\n",
      "\n",
      "Epoch:    4/10    Loss: 3.642296371459961\n",
      "\n",
      "Epoch:    4/10    Loss: 3.551941041946411\n",
      "\n",
      "Epoch:    4/10    Loss: 3.343943614959717\n",
      "\n",
      "Epoch:    4/10    Loss: 3.292179660797119\n",
      "\n",
      "Epoch:    4/10    Loss: 3.202264652252197\n",
      "\n",
      "Epoch:    4/10    Loss: 3.554388084411621\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4196072006225586\n",
      "\n",
      "Epoch:    4/10    Loss: 3.519899959564209\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4305305671691895\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3423991203308105\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4785685443878176\n",
      "\n",
      "Epoch:    4/10    Loss: 3.302824296951294\n",
      "\n",
      "Epoch:    4/10    Loss: 3.2881594371795653\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5203959560394287\n",
      "\n",
      "Epoch:    4/10    Loss: 3.574589977264404\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3565044021606445\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4329631614685057\n",
      "\n",
      "Epoch:    4/10    Loss: 3.0959620666503906\n",
      "\n",
      "Epoch:    4/10    Loss: 3.295444984436035\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3714475727081297\n",
      "\n",
      "Epoch:    4/10    Loss: 3.582411756515503\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3983107662200926\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4625135803222657\n",
      "\n",
      "Epoch:    4/10    Loss: 3.283187074661255\n",
      "\n",
      "Epoch:    4/10    Loss: 3.1320419692993164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    4/10    Loss: 3.444742202758789\n",
      "\n",
      "Epoch:    4/10    Loss: 3.50009596824646\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5060964393615723\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6478913402557374\n",
      "\n",
      "Epoch:    4/10    Loss: 3.593132972717285\n",
      "\n",
      "Epoch:    4/10    Loss: 3.565884132385254\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6084234523773193\n",
      "\n",
      "Epoch:    4/10    Loss: 3.543397693634033\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3228695964813233\n",
      "\n",
      "Epoch:    4/10    Loss: 3.472903251647949\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4525343418121337\n",
      "\n",
      "Epoch:    4/10    Loss: 3.453667154312134\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7792845344543458\n",
      "\n",
      "Epoch:    4/10    Loss: 3.567685451507568\n",
      "\n",
      "Epoch:    4/10    Loss: 3.548663396835327\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3715814304351808\n",
      "\n",
      "Epoch:    4/10    Loss: 3.498967523574829\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6535785579681397\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5621970176696776\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3778461265563964\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6067665004730225\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6311876487731936\n",
      "\n",
      "Epoch:    4/10    Loss: 3.675413646697998\n",
      "\n",
      "Epoch:    4/10    Loss: 3.588984041213989\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6416812992095946\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4843234539031984\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4691395378112793\n",
      "\n",
      "Epoch:    4/10    Loss: 3.473867111206055\n",
      "\n",
      "Epoch:    4/10    Loss: 3.444666290283203\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5249195289611817\n",
      "\n",
      "Epoch:    4/10    Loss: 3.684028034210205\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6135490417480467\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4053518390655517\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6775085067749025\n",
      "\n",
      "Epoch:    4/10    Loss: 3.551504020690918\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4140812873840334\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6207468032836916\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5873104095458985\n",
      "\n",
      "Epoch:    4/10    Loss: 3.321552028656006\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6180538272857667\n",
      "\n",
      "Epoch:    4/10    Loss: 3.444649896621704\n",
      "\n",
      "Epoch:    4/10    Loss: 3.709761924743652\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5047669315338137\n",
      "\n",
      "Epoch:    4/10    Loss: 3.49306902885437\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4452600288391113\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5931540870666505\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5017998600006104\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5982483768463136\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4981749439239502\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4156539630889893\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4098316764831544\n",
      "\n",
      "Epoch:    4/10    Loss: 3.615450716018677\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7604970645904543\n",
      "\n",
      "Epoch:    4/10    Loss: 3.499902629852295\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4389902687072755\n",
      "\n",
      "Epoch:    4/10    Loss: 3.443485689163208\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3761540126800536\n",
      "\n",
      "Epoch:    4/10    Loss: 3.7364492988586426\n",
      "\n",
      "Epoch:    4/10    Loss: 3.510733814239502\n",
      "\n",
      "Epoch:    4/10    Loss: 3.460664081573486\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5041646766662597\n",
      "\n",
      "Epoch:    4/10    Loss: 3.537477283477783\n",
      "\n",
      "Epoch:    4/10    Loss: 3.453101453781128\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3511556243896483\n",
      "\n",
      "Epoch:    4/10    Loss: 3.662506551742554\n",
      "\n",
      "Epoch:    4/10    Loss: 3.555629825592041\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4251951026916503\n",
      "\n",
      "Epoch:    4/10    Loss: 3.347457780838013\n",
      "\n",
      "Epoch:    4/10    Loss: 3.500543918609619\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6571970176696778\n",
      "\n",
      "Epoch:    4/10    Loss: 3.6228941822052003\n",
      "\n",
      "Epoch:    4/10    Loss: 3.5464701366424563\n",
      "\n",
      "Epoch:    4/10    Loss: 3.472245693206787\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3568217182159423\n",
      "\n",
      "Epoch:    4/10    Loss: 3.27238224029541\n",
      "\n",
      "Epoch:    4/10    Loss: 3.474208965301514\n",
      "\n",
      "Epoch:    4/10    Loss: 3.3103432846069336\n",
      "\n",
      "Epoch:    4/10    Loss: 3.4072800922393798\n",
      "\n",
      "Epoch:    4/10    Loss: 3.8250492572784425\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    5/10    Loss: 3.693213318669519\n",
      "\n",
      "Epoch:    5/10    Loss: 3.569367151260376\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1173899364471436\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5716516304016115\n",
      "\n",
      "Epoch:    5/10    Loss: 3.324366054534912\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3266205310821535\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5149150466918946\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3329157543182375\n",
      "\n",
      "Epoch:    5/10    Loss: 3.50608473777771\n",
      "\n",
      "Epoch:    5/10    Loss: 3.322479457855225\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4985266399383543\n",
      "\n",
      "Epoch:    5/10    Loss: 3.328381280899048\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4405600929260256\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2515318298339846\n",
      "\n",
      "Epoch:    5/10    Loss: 3.40325457572937\n",
      "\n",
      "Epoch:    5/10    Loss: 3.503021411895752\n",
      "\n",
      "Epoch:    5/10    Loss: 3.198244342803955\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4594280910491944\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4407521438598634\n",
      "\n",
      "Epoch:    5/10    Loss: 3.419618091583252\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2534505844116213\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3919622230529787\n",
      "\n",
      "Epoch:    5/10    Loss: 3.515050058364868\n",
      "\n",
      "Epoch:    5/10    Loss: 3.469029760360718\n",
      "\n",
      "Epoch:    5/10    Loss: 3.410572118759155\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6261207962036135\n",
      "\n",
      "Epoch:    5/10    Loss: 3.295132055282593\n",
      "\n",
      "Epoch:    5/10    Loss: 3.544375638961792\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4235556888580323\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2041338729858397\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5534512329101564\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3176784038543703\n",
      "\n",
      "Epoch:    5/10    Loss: 3.77590313911438\n",
      "\n",
      "Epoch:    5/10    Loss: 3.572620601654053\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3701453495025633\n",
      "\n",
      "Epoch:    5/10    Loss: 3.235967025756836\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1837425518035887\n",
      "\n",
      "Epoch:    5/10    Loss: 3.187151622772217\n",
      "\n",
      "Epoch:    5/10    Loss: 3.276669292449951\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3648520946502685\n",
      "\n",
      "Epoch:    5/10    Loss: 3.116304759979248\n",
      "\n",
      "Epoch:    5/10    Loss: 3.195700569152832\n",
      "\n",
      "Epoch:    5/10    Loss: 3.366439142227173\n",
      "\n",
      "Epoch:    5/10    Loss: 3.371429042816162\n",
      "\n",
      "Epoch:    5/10    Loss: 3.7346653366088867\n",
      "\n",
      "Epoch:    5/10    Loss: 3.447057294845581\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2854200267791747\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4319247245788573\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1533298969268797\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3875997161865232\n",
      "\n",
      "Epoch:    5/10    Loss: 3.433372583389282\n",
      "\n",
      "Epoch:    5/10    Loss: 3.390120658874512\n",
      "\n",
      "Epoch:    5/10    Loss: 3.424202699661255\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3145547485351563\n",
      "\n",
      "Epoch:    5/10    Loss: 3.327590618133545\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2379395866394045\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2017110443115233\n",
      "\n",
      "Epoch:    5/10    Loss: 3.14351993560791\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1459383869171145\n",
      "\n",
      "Epoch:    5/10    Loss: 3.232933883666992\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3178185081481932\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3454022789001465\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3421019172668456\n",
      "\n",
      "Epoch:    5/10    Loss: 3.0757298183441164\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2161112594604493\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2321994876861573\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2077317523956297\n",
      "\n",
      "Epoch:    5/10    Loss: 3.347580060958862\n",
      "\n",
      "Epoch:    5/10    Loss: 3.149422607421875\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2081852626800536\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2939702701568603\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2889356327056887\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2574064350128173\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3137290477752686\n",
      "\n",
      "Epoch:    5/10    Loss: 3.338900508880615\n",
      "\n",
      "Epoch:    5/10    Loss: 3.196746950149536\n",
      "\n",
      "Epoch:    5/10    Loss: 3.457771883010864\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1998450183868408\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2308245086669922\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5382222080230714\n",
      "\n",
      "Epoch:    5/10    Loss: 3.273799295425415\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6287464618682863\n",
      "\n",
      "Epoch:    5/10    Loss: 3.475757637023926\n",
      "\n",
      "Epoch:    5/10    Loss: 3.310573787689209\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3014984226226805\n",
      "\n",
      "Epoch:    5/10    Loss: 3.200422191619873\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2753887939453126\n",
      "\n",
      "Epoch:    5/10    Loss: 3.490620594024658\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3256981658935545\n",
      "\n",
      "Epoch:    5/10    Loss: 3.153902530670166\n",
      "\n",
      "Epoch:    5/10    Loss: 3.347703790664673\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2716158390045167\n",
      "\n",
      "Epoch:    5/10    Loss: 3.272018461227417\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2261460781097413\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2802018833160402\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2553543853759765\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2637179565429686\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4032703018188477\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1456938362121583\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2379353523254393\n",
      "\n",
      "Epoch:    5/10    Loss: 3.471196384429932\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2893115043640138\n",
      "\n",
      "Epoch:    5/10    Loss: 3.253164005279541\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3004588317871093\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5551783561706545\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6287096691131593\n",
      "\n",
      "Epoch:    5/10    Loss: 3.494105968475342\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2683864498138426\n",
      "\n",
      "Epoch:    5/10    Loss: 3.165239887237549\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    5/10    Loss: 3.3461565589904785\n",
      "\n",
      "Epoch:    5/10    Loss: 3.323132953643799\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3111040210723877\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3021998500823972\n",
      "\n",
      "Epoch:    5/10    Loss: 3.305191297531128\n",
      "\n",
      "Epoch:    5/10    Loss: 3.435791015625\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3628313064575197\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4747833728790285\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3666272926330567\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5681373023986818\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5014039039611817\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5122242259979246\n",
      "\n",
      "Epoch:    5/10    Loss: 3.380598478317261\n",
      "\n",
      "Epoch:    5/10    Loss: 3.513636283874512\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3700386238098146\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2576609325408934\n",
      "\n",
      "Epoch:    5/10    Loss: 3.095932970046997\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4046293926239013\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3897065925598144\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3677084636688233\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3497858238220215\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4257525539398195\n",
      "\n",
      "Epoch:    5/10    Loss: 3.274836540222168\n",
      "\n",
      "Epoch:    5/10    Loss: 3.39225040435791\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3448704624176027\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3480509090423585\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2083049774169923\n",
      "\n",
      "Epoch:    5/10    Loss: 3.233145351409912\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3245700550079347\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2422556018829347\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1626404094696046\n",
      "\n",
      "Epoch:    5/10    Loss: 3.186863594055176\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1902175045013426\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1609329319000246\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3963796997070315\n",
      "\n",
      "Epoch:    5/10    Loss: 3.136461000442505\n",
      "\n",
      "Epoch:    5/10    Loss: 3.357517719268799\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1831532192230223\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5235663795471193\n",
      "\n",
      "Epoch:    5/10    Loss: 3.24184889793396\n",
      "\n",
      "Epoch:    5/10    Loss: 3.450808115005493\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5198857307434084\n",
      "\n",
      "Epoch:    5/10    Loss: 3.337045421600342\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2227159786224364\n",
      "\n",
      "Epoch:    5/10    Loss: 3.202801389694214\n",
      "\n",
      "Epoch:    5/10    Loss: 3.234638795852661\n",
      "\n",
      "Epoch:    5/10    Loss: 3.300848798751831\n",
      "\n",
      "Epoch:    5/10    Loss: 3.308560304641724\n",
      "\n",
      "Epoch:    5/10    Loss: 3.0676870059967043\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2220588970184325\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1660216999053956\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1744619464874266\n",
      "\n",
      "Epoch:    5/10    Loss: 3.0170885562896728\n",
      "\n",
      "Epoch:    5/10    Loss: 3.185134630203247\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3878092479705813\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1680409908294678\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2762255859375\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3175938320159912\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1849375057220457\n",
      "\n",
      "Epoch:    5/10    Loss: 3.5105976390838625\n",
      "\n",
      "Epoch:    5/10    Loss: 3.0733444595336916\n",
      "\n",
      "Epoch:    5/10    Loss: 3.0506048583984375\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3159507846832277\n",
      "\n",
      "Epoch:    5/10    Loss: 3.300156526565552\n",
      "\n",
      "Epoch:    5/10    Loss: 3.302383403778076\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4811030578613282\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3696904087066653\n",
      "\n",
      "Epoch:    5/10    Loss: 3.164316997528076\n",
      "\n",
      "Epoch:    5/10    Loss: 3.145768575668335\n",
      "\n",
      "Epoch:    5/10    Loss: 3.033562698364258\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3827882480621336\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2511642169952393\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3313801765441893\n",
      "\n",
      "Epoch:    5/10    Loss: 3.290505247116089\n",
      "\n",
      "Epoch:    5/10    Loss: 3.21262246131897\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2968015098571777\n",
      "\n",
      "Epoch:    5/10    Loss: 3.16243408203125\n",
      "\n",
      "Epoch:    5/10    Loss: 3.177383317947388\n",
      "\n",
      "Epoch:    5/10    Loss: 3.374721174240112\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4249306678771974\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2556660270690916\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2763782119750977\n",
      "\n",
      "Epoch:    5/10    Loss: 2.9386792469024656\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1372773265838623\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2272660732269287\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4164288330078123\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2479395961761472\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2981796741485594\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1737949085235595\n",
      "\n",
      "Epoch:    5/10    Loss: 2.9918606758117674\n",
      "\n",
      "Epoch:    5/10    Loss: 3.332166624069214\n",
      "\n",
      "Epoch:    5/10    Loss: 3.370489892959595\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3483838272094726\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4974901390075686\n",
      "\n",
      "Epoch:    5/10    Loss: 3.459450054168701\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4479854583740233\n",
      "\n",
      "Epoch:    5/10    Loss: 3.488072385787964\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4123263454437254\n",
      "\n",
      "Epoch:    5/10    Loss: 3.19547833442688\n",
      "\n",
      "Epoch:    5/10    Loss: 3.332994203567505\n",
      "\n",
      "Epoch:    5/10    Loss: 3.304516763687134\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2742998218536377\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6466523742675783\n",
      "\n",
      "Epoch:    5/10    Loss: 3.408501958847046\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3523580837249756\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1925371265411377\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3146988677978517\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4527860927581786\n",
      "\n",
      "Epoch:    5/10    Loss: 3.379443483352661\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2281655979156496\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4614967250823976\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4718925380706787\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4913766765594483\n",
      "\n",
      "Epoch:    5/10    Loss: 3.387864418029785\n",
      "\n",
      "Epoch:    5/10    Loss: 3.51131293296814\n",
      "\n",
      "Epoch:    5/10    Loss: 3.319221534729004\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3534872722625733\n",
      "\n",
      "Epoch:    5/10    Loss: 3.361985969543457\n",
      "\n",
      "Epoch:    5/10    Loss: 3.30407675743103\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4145769119262694\n",
      "\n",
      "Epoch:    5/10    Loss: 3.559354829788208\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4734009170532225\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2688755226135253\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4954092788696287\n",
      "\n",
      "Epoch:    5/10    Loss: 3.403013687133789\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2640580558776855\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4635869884490966\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4076532173156737\n",
      "\n",
      "Epoch:    5/10    Loss: 3.149341974258423\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4479853439331056\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3309733390808107\n",
      "\n",
      "Epoch:    5/10    Loss: 3.559917345046997\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3369653034210205\n",
      "\n",
      "Epoch:    5/10    Loss: 3.360086536407471\n",
      "\n",
      "Epoch:    5/10    Loss: 3.326771593093872\n",
      "\n",
      "Epoch:    5/10    Loss: 3.407262601852417\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3107870292663573\n",
      "\n",
      "Epoch:    5/10    Loss: 3.450384063720703\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4206876373291015\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2689793872833253\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2488009834289553\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4530616664886473\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6679657173156737\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3708744716644286\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2954189205169677\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2965015983581543\n",
      "\n",
      "Epoch:    5/10    Loss: 3.240297546386719\n",
      "\n",
      "Epoch:    5/10    Loss: 3.506178789138794\n",
      "\n",
      "Epoch:    5/10    Loss: 3.323273639678955\n",
      "\n",
      "Epoch:    5/10    Loss: 3.367730903625488\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3641511535644533\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3861985111236574\n",
      "\n",
      "Epoch:    5/10    Loss: 3.320579481124878\n",
      "\n",
      "Epoch:    5/10    Loss: 3.218189296722412\n",
      "\n",
      "Epoch:    5/10    Loss: 3.526558952331543\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4444811058044436\n",
      "\n",
      "Epoch:    5/10    Loss: 3.253826379776001\n",
      "\n",
      "Epoch:    5/10    Loss: 3.204637908935547\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3453171348571775\n",
      "\n",
      "Epoch:    5/10    Loss: 3.496951847076416\n",
      "\n",
      "Epoch:    5/10    Loss: 3.4542940521240233\n",
      "\n",
      "Epoch:    5/10    Loss: 3.370955772399902\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3347223091125486\n",
      "\n",
      "Epoch:    5/10    Loss: 3.214910078048706\n",
      "\n",
      "Epoch:    5/10    Loss: 3.143369607925415\n",
      "\n",
      "Epoch:    5/10    Loss: 3.3110885715484617\n",
      "\n",
      "Epoch:    5/10    Loss: 3.1995350456237794\n",
      "\n",
      "Epoch:    5/10    Loss: 3.2657549381256104\n",
      "\n",
      "Epoch:    5/10    Loss: 3.6104776859283447\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    6/10    Loss: 3.5295067055280818\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4666419982910157\n",
      "\n",
      "Epoch:    6/10    Loss: 3.016383771896362\n",
      "\n",
      "Epoch:    6/10    Loss: 3.451001214981079\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1926456451416017\n",
      "\n",
      "Epoch:    6/10    Loss: 3.194570665359497\n",
      "\n",
      "Epoch:    6/10    Loss: 3.367758560180664\n",
      "\n",
      "Epoch:    6/10    Loss: 3.22654167175293\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4068911838531495\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2082363986968994\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3800142765045167\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2042486572265627\n",
      "\n",
      "Epoch:    6/10    Loss: 3.345857973098755\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1559271907806394\n",
      "\n",
      "Epoch:    6/10    Loss: 3.244590082168579\n",
      "\n",
      "Epoch:    6/10    Loss: 3.343406667709351\n",
      "\n",
      "Epoch:    6/10    Loss: 3.067717113494873\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3372276782989503\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3129700088500975\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    6/10    Loss: 3.2917465019226073\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1494665908813477\n",
      "\n",
      "Epoch:    6/10    Loss: 3.263115978240967\n",
      "\n",
      "Epoch:    6/10    Loss: 3.367147617340088\n",
      "\n",
      "Epoch:    6/10    Loss: 3.329588384628296\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3123309421539306\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4540579891204835\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2138937664031983\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4427390575408934\n",
      "\n",
      "Epoch:    6/10    Loss: 3.30248722076416\n",
      "\n",
      "Epoch:    6/10    Loss: 3.070039768218994\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3690363597869872\n",
      "\n",
      "Epoch:    6/10    Loss: 3.219815187454224\n",
      "\n",
      "Epoch:    6/10    Loss: 3.601640615463257\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4297446537017824\n",
      "\n",
      "Epoch:    6/10    Loss: 3.285623083114624\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1683569812774657\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0737389659881593\n",
      "\n",
      "Epoch:    6/10    Loss: 3.08734375\n",
      "\n",
      "Epoch:    6/10    Loss: 3.14971586227417\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2047055530548096\n",
      "\n",
      "Epoch:    6/10    Loss: 2.9964483261108397\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0461991119384764\n",
      "\n",
      "Epoch:    6/10    Loss: 3.232927360534668\n",
      "\n",
      "Epoch:    6/10    Loss: 3.240916328430176\n",
      "\n",
      "Epoch:    6/10    Loss: 3.6016353702545167\n",
      "\n",
      "Epoch:    6/10    Loss: 3.278351068496704\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1384233474731444\n",
      "\n",
      "Epoch:    6/10    Loss: 3.275618381500244\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0341097259521486\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2794133377075196\n",
      "\n",
      "Epoch:    6/10    Loss: 3.251480293273926\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2847540950775147\n",
      "\n",
      "Epoch:    6/10    Loss: 3.24977578163147\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2130383586883546\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2001084995269777\n",
      "\n",
      "Epoch:    6/10    Loss: 3.202825517654419\n",
      "\n",
      "Epoch:    6/10    Loss: 3.139843559265137\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0526507568359373\n",
      "\n",
      "Epoch:    6/10    Loss: 3.028604335784912\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0581701946258546\n",
      "\n",
      "Epoch:    6/10    Loss: 3.189665689468384\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2185858154296874\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2205797481536864\n",
      "\n",
      "Epoch:    6/10    Loss: 2.9522488117218018\n",
      "\n",
      "Epoch:    6/10    Loss: 3.094994602203369\n",
      "\n",
      "Epoch:    6/10    Loss: 3.108540105819702\n",
      "\n",
      "Epoch:    6/10    Loss: 3.076035509109497\n",
      "\n",
      "Epoch:    6/10    Loss: 3.205334491729736\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0624994468688964\n",
      "\n",
      "Epoch:    6/10    Loss: 3.092719707489014\n",
      "\n",
      "Epoch:    6/10    Loss: 3.185554389953613\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1635650062561034\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1256447315216063\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1828860950469973\n",
      "\n",
      "Epoch:    6/10    Loss: 3.19279203414917\n",
      "\n",
      "Epoch:    6/10    Loss: 3.124516487121582\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3411960315704348\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0672903156280515\n",
      "\n",
      "Epoch:    6/10    Loss: 3.073884334564209\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3687123012542726\n",
      "\n",
      "Epoch:    6/10    Loss: 3.12027717590332\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4493404960632326\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3574093627929686\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2083992290496828\n",
      "\n",
      "Epoch:    6/10    Loss: 3.130590515136719\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0825259017944338\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1931834506988523\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3169631958007812\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1863152313232423\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0425501918792723\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2071377563476564\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1346639251708983\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0986995029449464\n",
      "\n",
      "Epoch:    6/10    Loss: 3.154304904937744\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1717762470245363\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1376648998260497\n",
      "\n",
      "Epoch:    6/10    Loss: 3.152910623550415\n",
      "\n",
      "Epoch:    6/10    Loss: 3.289331865310669\n",
      "\n",
      "Epoch:    6/10    Loss: 3.02868634223938\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1292405986785887\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2981739902496336\n",
      "\n",
      "Epoch:    6/10    Loss: 3.170590667724609\n",
      "\n",
      "Epoch:    6/10    Loss: 3.151351490020752\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1828205394744873\n",
      "\n",
      "Epoch:    6/10    Loss: 3.391577625274658\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4627859497070315\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3611561107635497\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1768668365478514\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0473437976837157\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2746156787872316\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2349410915374754\n",
      "\n",
      "Epoch:    6/10    Loss: 3.197139711380005\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1968311977386477\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1848507022857664\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2660578441619874\n",
      "\n",
      "Epoch:    6/10    Loss: 3.266991472244263\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3654111289978026\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2385175609588623\n",
      "\n",
      "Epoch:    6/10    Loss: 3.397194128036499\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3676836776733396\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3609368419647216\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2763596248626707\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4023770809173586\n",
      "\n",
      "Epoch:    6/10    Loss: 3.260433359146118\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1436649417877196\n",
      "\n",
      "Epoch:    6/10    Loss: 3.015645809173584\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2784960079193115\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3140586853027343\n",
      "\n",
      "Epoch:    6/10    Loss: 3.268664951324463\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2068640327453615\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2540119457244874\n",
      "\n",
      "Epoch:    6/10    Loss: 3.12764928817749\n",
      "\n",
      "Epoch:    6/10    Loss: 3.267124528884888\n",
      "\n",
      "Epoch:    6/10    Loss: 3.247673234939575\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1821573829650878\n",
      "\n",
      "Epoch:    6/10    Loss: 3.075220909118652\n",
      "\n",
      "Epoch:    6/10    Loss: 3.107408971786499\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1801802921295166\n",
      "\n",
      "Epoch:    6/10    Loss: 3.141049919128418\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0188468170166014\n",
      "\n",
      "Epoch:    6/10    Loss: 3.108186712265015\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0370169258117676\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0748157405853274\n",
      "\n",
      "Epoch:    6/10    Loss: 3.234626407623291\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0181642150878907\n",
      "\n",
      "Epoch:    6/10    Loss: 3.209658422470093\n",
      "\n",
      "Epoch:    6/10    Loss: 3.037364377975464\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3815203285217286\n",
      "\n",
      "Epoch:    6/10    Loss: 3.118976650238037\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2907939529418946\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3898784923553467\n",
      "\n",
      "Epoch:    6/10    Loss: 3.199664945602417\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1150375270843504\n",
      "\n",
      "Epoch:    6/10    Loss: 3.100279674530029\n",
      "\n",
      "Epoch:    6/10    Loss: 3.115010347366333\n",
      "\n",
      "Epoch:    6/10    Loss: 3.184561824798584\n",
      "\n",
      "Epoch:    6/10    Loss: 3.202611970901489\n",
      "\n",
      "Epoch:    6/10    Loss: 2.980423355102539\n",
      "\n",
      "Epoch:    6/10    Loss: 3.098091621398926\n",
      "\n",
      "Epoch:    6/10    Loss: 3.079643363952637\n",
      "\n",
      "Epoch:    6/10    Loss: 2.9995151710510255\n",
      "\n",
      "Epoch:    6/10    Loss: 2.917522392272949\n",
      "\n",
      "Epoch:    6/10    Loss: 3.082953300476074\n",
      "\n",
      "Epoch:    6/10    Loss: 3.223600215911865\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0565311336517333\n",
      "\n",
      "Epoch:    6/10    Loss: 3.175158281326294\n",
      "\n",
      "Epoch:    6/10    Loss: 3.213083782196045\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0405575466156005\n",
      "\n",
      "Epoch:    6/10    Loss: 3.356845054626465\n",
      "\n",
      "Epoch:    6/10    Loss: 2.956803503036499\n",
      "\n",
      "Epoch:    6/10    Loss: 2.9557770538330077\n",
      "\n",
      "Epoch:    6/10    Loss: 3.167384386062622\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0923714351654055\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1284519958496095\n",
      "\n",
      "Epoch:    6/10    Loss: 3.344559268951416\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2011627769470214\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0351826477050783\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0634373569488527\n",
      "\n",
      "Epoch:    6/10    Loss: 2.9254544258117674\n",
      "\n",
      "Epoch:    6/10    Loss: 3.264467315673828\n",
      "\n",
      "Epoch:    6/10    Loss: 3.169620018005371\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2042475032806395\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1075480937957765\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0370190715789795\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1759175300598144\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0672995948791506\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0563846492767333\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2019672870635985\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3094775772094724\n",
      "\n",
      "Epoch:    6/10    Loss: 3.109892473220825\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1716495037078856\n",
      "\n",
      "Epoch:    6/10    Loss: 2.8569127368927\n",
      "\n",
      "Epoch:    6/10    Loss: 3.024758539199829\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1078450965881346\n",
      "\n",
      "Epoch:    6/10    Loss: 3.260155086517334\n",
      "\n",
      "Epoch:    6/10    Loss: 3.13282057762146\n",
      "\n",
      "Epoch:    6/10    Loss: 3.143766689300537\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0275787353515624\n",
      "\n",
      "Epoch:    6/10    Loss: 2.887307119369507\n",
      "\n",
      "Epoch:    6/10    Loss: 3.198784065246582\n",
      "\n",
      "Epoch:    6/10    Loss: 3.230763511657715\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2383088779449465\n",
      "\n",
      "Epoch:    6/10    Loss: 3.356265678405762\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3008392810821534\n",
      "\n",
      "Epoch:    6/10    Loss: 3.291660108566284\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3537488651275633\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2898975086212157\n",
      "\n",
      "Epoch:    6/10    Loss: 3.096609230041504\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    6/10    Loss: 3.1959156799316406\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1570423889160155\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1972844409942627\n",
      "\n",
      "Epoch:    6/10    Loss: 3.5121428108215333\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3067492389678956\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2285527324676515\n",
      "\n",
      "Epoch:    6/10    Loss: 3.080904245376587\n",
      "\n",
      "Epoch:    6/10    Loss: 3.20823052406311\n",
      "\n",
      "Epoch:    6/10    Loss: 3.309134349822998\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2254479789733885\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1106819248199464\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3293051052093507\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3142090320587156\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3220612144470216\n",
      "\n",
      "Epoch:    6/10    Loss: 3.223505039215088\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3664365577697755\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2244824981689453\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2026474571228025\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2554667377471924\n",
      "\n",
      "Epoch:    6/10    Loss: 3.156636266708374\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2913665676116945\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4273104763031004\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3831120109558106\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1788761901855467\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3964997577667235\n",
      "\n",
      "Epoch:    6/10    Loss: 3.241812219619751\n",
      "\n",
      "Epoch:    6/10    Loss: 3.125335865020752\n",
      "\n",
      "Epoch:    6/10    Loss: 3.312092523574829\n",
      "\n",
      "Epoch:    6/10    Loss: 3.279106378555298\n",
      "\n",
      "Epoch:    6/10    Loss: 3.043679666519165\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3263214111328123\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2586858749389647\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3844962406158445\n",
      "\n",
      "Epoch:    6/10    Loss: 3.248847970962524\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2292576313018797\n",
      "\n",
      "Epoch:    6/10    Loss: 3.202523584365845\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2647769927978514\n",
      "\n",
      "Epoch:    6/10    Loss: 3.189969940185547\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3213772583007812\n",
      "\n",
      "Epoch:    6/10    Loss: 3.251623945236206\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1305729961395263\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1484274005889894\n",
      "\n",
      "Epoch:    6/10    Loss: 3.300290651321411\n",
      "\n",
      "Epoch:    6/10    Loss: 3.4874593734741213\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2228159523010254\n",
      "\n",
      "Epoch:    6/10    Loss: 3.203119831085205\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1669851303100587\n",
      "\n",
      "Epoch:    6/10    Loss: 3.113399477005005\n",
      "\n",
      "Epoch:    6/10    Loss: 3.366528196334839\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1784058380126954\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2330276584625244\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2226011753082275\n",
      "\n",
      "Epoch:    6/10    Loss: 3.255729789733887\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1900603199005126\n",
      "\n",
      "Epoch:    6/10    Loss: 3.094983491897583\n",
      "\n",
      "Epoch:    6/10    Loss: 3.434110164642334\n",
      "\n",
      "Epoch:    6/10    Loss: 3.322557611465454\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1019795513153077\n",
      "\n",
      "Epoch:    6/10    Loss: 3.0713631916046142\n",
      "\n",
      "Epoch:    6/10    Loss: 3.200815258026123\n",
      "\n",
      "Epoch:    6/10    Loss: 3.340642280578613\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3183621406555175\n",
      "\n",
      "Epoch:    6/10    Loss: 3.265348024368286\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1868143272399903\n",
      "\n",
      "Epoch:    6/10    Loss: 3.074001293182373\n",
      "\n",
      "Epoch:    6/10    Loss: 3.015378293991089\n",
      "\n",
      "Epoch:    6/10    Loss: 3.2173869895935057\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1063429355621337\n",
      "\n",
      "Epoch:    6/10    Loss: 3.1472556686401365\n",
      "\n",
      "Epoch:    6/10    Loss: 3.3871527767181395\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    7/10    Loss: 3.387975282447283\n",
      "\n",
      "Epoch:    7/10    Loss: 3.335600357055664\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8897459220886232\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2826357746124266\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0816889953613282\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0790992736816407\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2600411224365233\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1209835052490233\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2846006107330323\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1162820720672606\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2538449001312255\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1228206539154053\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1760070514678955\n",
      "\n",
      "Epoch:    7/10    Loss: 3.032931251525879\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1288888168334963\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2460477352142334\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9793618869781495\n",
      "\n",
      "Epoch:    7/10    Loss: 3.259775972366333\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1926350498199465\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1804737281799316\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0594525146484375\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1421285343170164\n",
      "\n",
      "Epoch:    7/10    Loss: 3.226697635650635\n",
      "\n",
      "Epoch:    7/10    Loss: 3.23815788269043\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2223606300354004\n",
      "\n",
      "Epoch:    7/10    Loss: 3.3244036293029784\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1151678562164307\n",
      "\n",
      "Epoch:    7/10    Loss: 3.270256853103638\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2215833950042723\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9556882572174072\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2764192390441895\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1169852352142335\n",
      "\n",
      "Epoch:    7/10    Loss: 3.5006289100646972\n",
      "\n",
      "Epoch:    7/10    Loss: 3.290305643081665\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2130338382720947\n",
      "\n",
      "Epoch:    7/10    Loss: 3.050939874649048\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9985702419281006\n",
      "\n",
      "Epoch:    7/10    Loss: 2.948421812057495\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0658940410614015\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1003090286254884\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9029854488372804\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9377682399749756\n",
      "\n",
      "Epoch:    7/10    Loss: 3.134964904785156\n",
      "\n",
      "Epoch:    7/10    Loss: 3.123944044113159\n",
      "\n",
      "Epoch:    7/10    Loss: 3.462358160018921\n",
      "\n",
      "Epoch:    7/10    Loss: 3.168193655014038\n",
      "\n",
      "Epoch:    7/10    Loss: 3.069216070175171\n",
      "\n",
      "Epoch:    7/10    Loss: 3.191146764755249\n",
      "\n",
      "Epoch:    7/10    Loss: 2.99239182472229\n",
      "\n",
      "Epoch:    7/10    Loss: 3.167579536437988\n",
      "\n",
      "Epoch:    7/10    Loss: 3.171229763031006\n",
      "\n",
      "Epoch:    7/10    Loss: 3.180966329574585\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1333061408996583\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0926581764221193\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1070222091674804\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0357178115844725\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0246888637542724\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9404113578796385\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9287922096252443\n",
      "\n",
      "Epoch:    7/10    Loss: 2.960694417953491\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0570925807952882\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0981311321258547\n",
      "\n",
      "Epoch:    7/10    Loss: 3.08345064163208\n",
      "\n",
      "Epoch:    7/10    Loss: 2.870790729522705\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9858026695251465\n",
      "\n",
      "Epoch:    7/10    Loss: 3.006621952056885\n",
      "\n",
      "Epoch:    7/10    Loss: 3.008867816925049\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1100987243652343\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9604473686218262\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0069598865509035\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0630636405944824\n",
      "\n",
      "Epoch:    7/10    Loss: 3.026026391983032\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0181179332733152\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0582180881500243\n",
      "\n",
      "Epoch:    7/10    Loss: 3.095269937515259\n",
      "\n",
      "Epoch:    7/10    Loss: 3.001348991394043\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2518553066253664\n",
      "\n",
      "Epoch:    7/10    Loss: 3.001262273788452\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0301885318756105\n",
      "\n",
      "Epoch:    7/10    Loss: 3.254499397277832\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0171247577667235\n",
      "\n",
      "Epoch:    7/10    Loss: 3.3069652462005616\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2162975692749023\n",
      "\n",
      "Epoch:    7/10    Loss: 3.089559965133667\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0380763530731203\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9697059535980226\n",
      "\n",
      "Epoch:    7/10    Loss: 3.055048942565918\n",
      "\n",
      "Epoch:    7/10    Loss: 3.203344850540161\n",
      "\n",
      "Epoch:    7/10    Loss: 3.096235227584839\n",
      "\n",
      "Epoch:    7/10    Loss: 2.920963640213013\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1103432083129885\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9753135871887206\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9840289783477782\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0336224460601806\n",
      "\n",
      "Epoch:    7/10    Loss: 3.059659423828125\n",
      "\n",
      "Epoch:    7/10    Loss: 3.075630168914795\n",
      "\n",
      "Epoch:    7/10    Loss: 3.053964834213257\n",
      "\n",
      "Epoch:    7/10    Loss: 3.176196174621582\n",
      "\n",
      "Epoch:    7/10    Loss: 2.950159568786621\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0182189464569094\n",
      "\n",
      "Epoch:    7/10    Loss: 3.171525297164917\n",
      "\n",
      "Epoch:    7/10    Loss: 3.049585247039795\n",
      "\n",
      "Epoch:    7/10    Loss: 3.049388036727905\n",
      "\n",
      "Epoch:    7/10    Loss: 3.105612726211548\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2868451976776125\n",
      "\n",
      "Epoch:    7/10    Loss: 3.3485234642028807\n",
      "\n",
      "Epoch:    7/10    Loss: 3.253988494873047\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0704131889343262\n",
      "\n",
      "Epoch:    7/10    Loss: 2.95378191947937\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1709607887268065\n",
      "\n",
      "Epoch:    7/10    Loss: 3.108186388015747\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0718426418304445\n",
      "\n",
      "Epoch:    7/10    Loss: 3.102320518493652\n",
      "\n",
      "Epoch:    7/10    Loss: 3.121756057739258\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1327793312072756\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1089117240905764\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2645854473114015\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1103487491607664\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    7/10    Loss: 3.256998300552368\n",
      "\n",
      "Epoch:    7/10    Loss: 3.247326250076294\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2803551864624025\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1945656299591065\n",
      "\n",
      "Epoch:    7/10    Loss: 3.3072601795196532\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1302590560913086\n",
      "\n",
      "Epoch:    7/10    Loss: 3.064704532623291\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8998407459259035\n",
      "\n",
      "Epoch:    7/10    Loss: 3.163090648651123\n",
      "\n",
      "Epoch:    7/10    Loss: 3.199906940460205\n",
      "\n",
      "Epoch:    7/10    Loss: 3.206792335510254\n",
      "\n",
      "Epoch:    7/10    Loss: 3.150126552581787\n",
      "\n",
      "Epoch:    7/10    Loss: 3.135611448287964\n",
      "\n",
      "Epoch:    7/10    Loss: 3.006799898147583\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1567585945129393\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1178363037109373\n",
      "\n",
      "Epoch:    7/10    Loss: 3.081057062149048\n",
      "\n",
      "Epoch:    7/10    Loss: 2.977402505874634\n",
      "\n",
      "Epoch:    7/10    Loss: 3.00807728767395\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0695602798461916\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9927141284942627\n",
      "\n",
      "Epoch:    7/10    Loss: 2.955459032058716\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9622770309448243\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9532613372802734\n",
      "\n",
      "Epoch:    7/10    Loss: 2.918392562866211\n",
      "\n",
      "Epoch:    7/10    Loss: 3.076293830871582\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9279065704345704\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1180270099639893\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9180656147003172\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2287439632415773\n",
      "\n",
      "Epoch:    7/10    Loss: 3.053767557144165\n",
      "\n",
      "Epoch:    7/10    Loss: 3.18841420173645\n",
      "\n",
      "Epoch:    7/10    Loss: 3.257842025756836\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1219791316986085\n",
      "\n",
      "Epoch:    7/10    Loss: 3.014694242477417\n",
      "\n",
      "Epoch:    7/10    Loss: 2.985499258041382\n",
      "\n",
      "Epoch:    7/10    Loss: 3.043315944671631\n",
      "\n",
      "Epoch:    7/10    Loss: 3.052805852890015\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0796140956878664\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8995085048675535\n",
      "\n",
      "Epoch:    7/10    Loss: 3.061353254318237\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9629350185394285\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8734885120391844\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8228324031829835\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0364328098297118\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1198833656311034\n",
      "\n",
      "Epoch:    7/10    Loss: 2.954578275680542\n",
      "\n",
      "Epoch:    7/10    Loss: 3.095826587677002\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1282208251953123\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9593124771118164\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2192544651031496\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8751479625701903\n",
      "\n",
      "Epoch:    7/10    Loss: 2.846309251785278\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0724596691131594\n",
      "\n",
      "Epoch:    7/10    Loss: 2.988428039550781\n",
      "\n",
      "Epoch:    7/10    Loss: 3.021408338546753\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2570625495910646\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0662880516052247\n",
      "\n",
      "Epoch:    7/10    Loss: 2.931532611846924\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9357422161102296\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8173252010345458\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1297801780700683\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0402887725830077\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1552691745758055\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0801530838012696\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9277434730529786\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0566102504730224\n",
      "\n",
      "Epoch:    7/10    Loss: 2.917438478469849\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9355030059814453\n",
      "\n",
      "Epoch:    7/10    Loss: 3.136932125091553\n",
      "\n",
      "Epoch:    7/10    Loss: 3.182367458343506\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9969472694396972\n",
      "\n",
      "Epoch:    7/10    Loss: 3.040626440048218\n",
      "\n",
      "Epoch:    7/10    Loss: 2.780832691192627\n",
      "\n",
      "Epoch:    7/10    Loss: 2.940773811340332\n",
      "\n",
      "Epoch:    7/10    Loss: 3.020244541168213\n",
      "\n",
      "Epoch:    7/10    Loss: 3.162959432601929\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0111453342437744\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0564346885681153\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9769474124908446\n",
      "\n",
      "Epoch:    7/10    Loss: 2.8041888427734376\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1403926277160643\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1209107303619383\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1433139133453367\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2430296611785887\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1700640678405763\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2258694648742674\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2468744564056395\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1905988883972167\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9864654636383055\n",
      "\n",
      "Epoch:    7/10    Loss: 3.086602602005005\n",
      "\n",
      "Epoch:    7/10    Loss: 3.061547918319702\n",
      "\n",
      "Epoch:    7/10    Loss: 3.039726667404175\n",
      "\n",
      "Epoch:    7/10    Loss: 3.367441663742065\n",
      "\n",
      "Epoch:    7/10    Loss: 3.195941934585571\n",
      "\n",
      "Epoch:    7/10    Loss: 3.106882438659668\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9714735412597655\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0798717403411864\n",
      "\n",
      "Epoch:    7/10    Loss: 3.185181694030762\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1239332962036133\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0099405670166015\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1857139015197755\n",
      "\n",
      "Epoch:    7/10    Loss: 3.197073497772217\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1819036483764647\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0709646797180175\n",
      "\n",
      "Epoch:    7/10    Loss: 3.207199745178223\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1393813133239745\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0613863468170166\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1379596900939943\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0754313182830813\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1489283561706545\n",
      "\n",
      "Epoch:    7/10    Loss: 3.285936784744263\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2686564254760744\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0970711803436277\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2862039852142333\n",
      "\n",
      "Epoch:    7/10    Loss: 3.147165231704712\n",
      "\n",
      "Epoch:    7/10    Loss: 3.021367244720459\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1838753700256346\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1560578536987305\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9196555042266845\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2026230239868165\n",
      "\n",
      "Epoch:    7/10    Loss: 3.143969955444336\n",
      "\n",
      "Epoch:    7/10    Loss: 3.267993841171265\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1452843379974365\n",
      "\n",
      "Epoch:    7/10    Loss: 3.128203887939453\n",
      "\n",
      "Epoch:    7/10    Loss: 3.101543140411377\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1354848861694338\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0826226091384887\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1929029846191406\n",
      "\n",
      "Epoch:    7/10    Loss: 3.119211139678955\n",
      "\n",
      "Epoch:    7/10    Loss: 2.992829008102417\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0809929180145263\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1754629516601565\n",
      "\n",
      "Epoch:    7/10    Loss: 3.395430727005005\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1381590747833252\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0503395938873292\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0546257877349854\n",
      "\n",
      "Epoch:    7/10    Loss: 3.017951765060425\n",
      "\n",
      "Epoch:    7/10    Loss: 3.213292369842529\n",
      "\n",
      "Epoch:    7/10    Loss: 3.072159194946289\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1534377479553224\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1224536895751953\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1657450294494627\n",
      "\n",
      "Epoch:    7/10    Loss: 3.08495774269104\n",
      "\n",
      "Epoch:    7/10    Loss: 2.976745910644531\n",
      "\n",
      "Epoch:    7/10    Loss: 3.2969374465942383\n",
      "\n",
      "Epoch:    7/10    Loss: 3.246799373626709\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0319438076019285\n",
      "\n",
      "Epoch:    7/10    Loss: 2.965582046508789\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0776424312591555\n",
      "\n",
      "Epoch:    7/10    Loss: 3.188943099975586\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1883802032470703\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1013482093811033\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0876705169677736\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9917158031463624\n",
      "\n",
      "Epoch:    7/10    Loss: 2.9034733676910403\n",
      "\n",
      "Epoch:    7/10    Loss: 3.1163109493255616\n",
      "\n",
      "Epoch:    7/10    Loss: 3.019342079162598\n",
      "\n",
      "Epoch:    7/10    Loss: 3.0591346883773802\n",
      "\n",
      "Epoch:    7/10    Loss: 3.245071029663086\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    8/10    Loss: 3.266211886738622\n",
      "\n",
      "Epoch:    8/10    Loss: 3.2310764503479006\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8013629341125488\n",
      "\n",
      "Epoch:    8/10    Loss: 3.155302810668945\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9773155212402345\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0027458763122556\n",
      "\n",
      "Epoch:    8/10    Loss: 3.141804838180542\n",
      "\n",
      "Epoch:    8/10    Loss: 3.036230134963989\n",
      "\n",
      "Epoch:    8/10    Loss: 3.227839708328247\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0395185947418213\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1611775302886964\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0010297203063967\n",
      "\n",
      "Epoch:    8/10    Loss: 3.083318119049072\n",
      "\n",
      "Epoch:    8/10    Loss: 2.957053575515747\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0149632263183594\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1304612922668458\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9080869007110595\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1358527660369875\n",
      "\n",
      "Epoch:    8/10    Loss: 3.085545787811279\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0762880992889405\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9407995319366456\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0573991203308104\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1535090351104738\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1410890865325927\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0725041961669923\n",
      "\n",
      "Epoch:    8/10    Loss: 3.2520703983306887\n",
      "\n",
      "Epoch:    8/10    Loss: 2.995796184539795\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1877420711517335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    8/10    Loss: 3.116751823425293\n",
      "\n",
      "Epoch:    8/10    Loss: 2.895250234603882\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1284564208984373\n",
      "\n",
      "Epoch:    8/10    Loss: 2.993426790237427\n",
      "\n",
      "Epoch:    8/10    Loss: 3.3826612281799315\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1601303386688233\n",
      "\n",
      "Epoch:    8/10    Loss: 3.077616014480591\n",
      "\n",
      "Epoch:    8/10    Loss: 2.921684808731079\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9669510078430177\n",
      "\n",
      "Epoch:    8/10    Loss: 2.89727126121521\n",
      "\n",
      "Epoch:    8/10    Loss: 2.973122825622559\n",
      "\n",
      "Epoch:    8/10    Loss: 2.992047805786133\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8293513298034667\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8415130138397218\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0271427631378174\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9828167533874512\n",
      "\n",
      "Epoch:    8/10    Loss: 3.345701036453247\n",
      "\n",
      "Epoch:    8/10    Loss: 3.088503532409668\n",
      "\n",
      "Epoch:    8/10    Loss: 2.974940881729126\n",
      "\n",
      "Epoch:    8/10    Loss: 3.09303503036499\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9312508296966553\n",
      "\n",
      "Epoch:    8/10    Loss: 3.099103422164917\n",
      "\n",
      "Epoch:    8/10    Loss: 3.055289554595947\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0917019939422605\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0318689346313477\n",
      "\n",
      "Epoch:    8/10    Loss: 3.001849708557129\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0020876693725587\n",
      "\n",
      "Epoch:    8/10    Loss: 2.969301223754883\n",
      "\n",
      "Epoch:    8/10    Loss: 2.97635931968689\n",
      "\n",
      "Epoch:    8/10    Loss: 2.941376876831055\n",
      "\n",
      "Epoch:    8/10    Loss: 2.905289649963379\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8803774166107177\n",
      "\n",
      "Epoch:    8/10    Loss: 2.942395725250244\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0033152389526365\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0047435665130617\n",
      "\n",
      "Epoch:    8/10    Loss: 2.778682565689087\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8809337997436524\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9582613372802733\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9584222507476805\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0172469329833986\n",
      "\n",
      "Epoch:    8/10    Loss: 2.878799171447754\n",
      "\n",
      "Epoch:    8/10    Loss: 2.914152488708496\n",
      "\n",
      "Epoch:    8/10    Loss: 2.991930379867554\n",
      "\n",
      "Epoch:    8/10    Loss: 2.949141149520874\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9379039096832273\n",
      "\n",
      "Epoch:    8/10    Loss: 3.019042797088623\n",
      "\n",
      "Epoch:    8/10    Loss: 2.999001121520996\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9133033466339113\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1295262813568114\n",
      "\n",
      "Epoch:    8/10    Loss: 2.956677017211914\n",
      "\n",
      "Epoch:    8/10    Loss: 2.908084897994995\n",
      "\n",
      "Epoch:    8/10    Loss: 3.122188014984131\n",
      "\n",
      "Epoch:    8/10    Loss: 2.927212610244751\n",
      "\n",
      "Epoch:    8/10    Loss: 3.216845836639404\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1384322929382322\n",
      "\n",
      "Epoch:    8/10    Loss: 3.007070388793945\n",
      "\n",
      "Epoch:    8/10    Loss: 2.967855157852173\n",
      "\n",
      "Epoch:    8/10    Loss: 2.877427864074707\n",
      "\n",
      "Epoch:    8/10    Loss: 2.935813236236572\n",
      "\n",
      "Epoch:    8/10    Loss: 3.090451173782349\n",
      "\n",
      "Epoch:    8/10    Loss: 3.007757139205933\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8777265167236328\n",
      "\n",
      "Epoch:    8/10    Loss: 2.962983388900757\n",
      "\n",
      "Epoch:    8/10    Loss: 2.88529426574707\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8995880317687988\n",
      "\n",
      "Epoch:    8/10    Loss: 2.933005485534668\n",
      "\n",
      "Epoch:    8/10    Loss: 2.969690942764282\n",
      "\n",
      "Epoch:    8/10    Loss: 2.99049147605896\n",
      "\n",
      "Epoch:    8/10    Loss: 2.938564968109131\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0882761001586916\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8772995853424073\n",
      "\n",
      "Epoch:    8/10    Loss: 2.933895616531372\n",
      "\n",
      "Epoch:    8/10    Loss: 3.068694486618042\n",
      "\n",
      "Epoch:    8/10    Loss: 2.969111080169678\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9451929569244384\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0163946533203125\n",
      "\n",
      "Epoch:    8/10    Loss: 3.144552869796753\n",
      "\n",
      "Epoch:    8/10    Loss: 3.199165906906128\n",
      "\n",
      "Epoch:    8/10    Loss: 3.147085094451904\n",
      "\n",
      "Epoch:    8/10    Loss: 3.020642786026001\n",
      "\n",
      "Epoch:    8/10    Loss: 2.929618854522705\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0624238014221192\n",
      "\n",
      "Epoch:    8/10    Loss: 2.989906415939331\n",
      "\n",
      "Epoch:    8/10    Loss: 3.014637508392334\n",
      "\n",
      "Epoch:    8/10    Loss: 3.023339958190918\n",
      "\n",
      "Epoch:    8/10    Loss: 3.00319993019104\n",
      "\n",
      "Epoch:    8/10    Loss: 2.995539779663086\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0557747077941895\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1324141883850096\n",
      "\n",
      "Epoch:    8/10    Loss: 3.05106201171875\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1593440341949464\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1543476581573486\n",
      "\n",
      "Epoch:    8/10    Loss: 3.171516170501709\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1043556213378904\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1791796684265137\n",
      "\n",
      "Epoch:    8/10    Loss: 3.078955249786377\n",
      "\n",
      "Epoch:    8/10    Loss: 2.986156015396118\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8529684925079346\n",
      "\n",
      "Epoch:    8/10    Loss: 3.040032148361206\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1188565731048583\n",
      "\n",
      "Epoch:    8/10    Loss: 3.097602491378784\n",
      "\n",
      "Epoch:    8/10    Loss: 2.983867073059082\n",
      "\n",
      "Epoch:    8/10    Loss: 3.046789665222168\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8930015182495117\n",
      "\n",
      "Epoch:    8/10    Loss: 3.061992540359497\n",
      "\n",
      "Epoch:    8/10    Loss: 3.074292097091675\n",
      "\n",
      "Epoch:    8/10    Loss: 2.969398508071899\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8919408416748045\n",
      "\n",
      "Epoch:    8/10    Loss: 2.907273645401001\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9556210708618162\n",
      "\n",
      "Epoch:    8/10    Loss: 2.88552188873291\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8743862438201906\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8863018417358397\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8581377696990966\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7670213890075686\n",
      "\n",
      "Epoch:    8/10    Loss: 2.996244649887085\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8483140659332276\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9987653827667238\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8209887886047365\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1115831565856933\n",
      "\n",
      "Epoch:    8/10    Loss: 2.983512830734253\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1062106704711914\n",
      "\n",
      "Epoch:    8/10    Loss: 3.177179260253906\n",
      "\n",
      "Epoch:    8/10    Loss: 2.998337354660034\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9391651153564453\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9086497974395753\n",
      "\n",
      "Epoch:    8/10    Loss: 2.960438117980957\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9561655426025393\n",
      "\n",
      "Epoch:    8/10    Loss: 2.94903302192688\n",
      "\n",
      "Epoch:    8/10    Loss: 2.794362726211548\n",
      "\n",
      "Epoch:    8/10    Loss: 2.93060585975647\n",
      "\n",
      "Epoch:    8/10    Loss: 2.909143533706665\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7486001014709474\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7728066349029543\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9522386264801024\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0650754737854005\n",
      "\n",
      "Epoch:    8/10    Loss: 2.888151502609253\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9898759746551513\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0005702686309816\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8487575244903565\n",
      "\n",
      "Epoch:    8/10    Loss: 3.092655448913574\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7990878582000733\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7887541675567626\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0076826572418214\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9198661136627195\n",
      "\n",
      "Epoch:    8/10    Loss: 2.901001377105713\n",
      "\n",
      "Epoch:    8/10    Loss: 3.111009569168091\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9465062332153322\n",
      "\n",
      "Epoch:    8/10    Loss: 2.827224464416504\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8252707290649415\n",
      "\n",
      "Epoch:    8/10    Loss: 2.736303615570068\n",
      "\n",
      "Epoch:    8/10    Loss: 3.029192190170288\n",
      "\n",
      "Epoch:    8/10    Loss: 2.912818126678467\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0090814876556395\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0149894905090333\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8424171733856203\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9689479064941406\n",
      "\n",
      "Epoch:    8/10    Loss: 2.815783004760742\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8674289703369142\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9970320987701418\n",
      "\n",
      "Epoch:    8/10    Loss: 3.070859422683716\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9102571201324463\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9595591735839846\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7129687595367433\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8770620346069338\n",
      "\n",
      "Epoch:    8/10    Loss: 2.93259407043457\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0262170791625977\n",
      "\n",
      "Epoch:    8/10    Loss: 2.955521364212036\n",
      "\n",
      "Epoch:    8/10    Loss: 2.94542631149292\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8500940704345705\n",
      "\n",
      "Epoch:    8/10    Loss: 2.7168115997314453\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0177725887298585\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0351641368865967\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0884685134887695\n",
      "\n",
      "Epoch:    8/10    Loss: 3.087844409942627\n",
      "\n",
      "Epoch:    8/10    Loss: 3.047360782623291\n",
      "\n",
      "Epoch:    8/10    Loss: 3.152585926055908\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1295156955718992\n",
      "\n",
      "Epoch:    8/10    Loss: 3.091356725692749\n",
      "\n",
      "Epoch:    8/10    Loss: 2.920652914047241\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9214820098876952\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9192519283294676\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9301562976837157\n",
      "\n",
      "Epoch:    8/10    Loss: 3.2592946243286134\n",
      "\n",
      "Epoch:    8/10    Loss: 3.057737417221069\n",
      "\n",
      "Epoch:    8/10    Loss: 2.999444799423218\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8853855895996094\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9867052173614503\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0950897121429444\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    8/10    Loss: 3.0327204990386964\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8934968280792237\n",
      "\n",
      "Epoch:    8/10    Loss: 3.072907361984253\n",
      "\n",
      "Epoch:    8/10    Loss: 3.053640432357788\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1091433906555177\n",
      "\n",
      "Epoch:    8/10    Loss: 2.960197114944458\n",
      "\n",
      "Epoch:    8/10    Loss: 3.100936059951782\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9823217582702637\n",
      "\n",
      "Epoch:    8/10    Loss: 2.931633024215698\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0497121238708496\n",
      "\n",
      "Epoch:    8/10    Loss: 2.923986110687256\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0374154472351074\n",
      "\n",
      "Epoch:    8/10    Loss: 3.2326363563537597\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1900796604156496\n",
      "\n",
      "Epoch:    8/10    Loss: 2.968314628601074\n",
      "\n",
      "Epoch:    8/10    Loss: 3.135648832321167\n",
      "\n",
      "Epoch:    8/10    Loss: 3.009718084335327\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9291623878479003\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0833190727233886\n",
      "\n",
      "Epoch:    8/10    Loss: 3.026272897720337\n",
      "\n",
      "Epoch:    8/10    Loss: 2.808734483718872\n",
      "\n",
      "Epoch:    8/10    Loss: 3.098991994857788\n",
      "\n",
      "Epoch:    8/10    Loss: 3.051898899078369\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1486995029449463\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9915334129333497\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0429078197479247\n",
      "\n",
      "Epoch:    8/10    Loss: 3.051818838119507\n",
      "\n",
      "Epoch:    8/10    Loss: 3.053245906829834\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9945169639587403\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0762964248657227\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0278592014312746\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9300343418121337\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9281506061553957\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0870469665527343\n",
      "\n",
      "Epoch:    8/10    Loss: 3.2527592372894287\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0318506717681886\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9833103084564208\n",
      "\n",
      "Epoch:    8/10    Loss: 2.951139221191406\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8984519100189208\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1275499439239502\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9503037548065185\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9948161220550538\n",
      "\n",
      "Epoch:    8/10    Loss: 3.02456205368042\n",
      "\n",
      "Epoch:    8/10    Loss: 3.059474105834961\n",
      "\n",
      "Epoch:    8/10    Loss: 2.97375789642334\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9050950145721437\n",
      "\n",
      "Epoch:    8/10    Loss: 3.199669351577759\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1294539833068846\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9285260009765626\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8669910049438476\n",
      "\n",
      "Epoch:    8/10    Loss: 2.998511304855347\n",
      "\n",
      "Epoch:    8/10    Loss: 3.094733247756958\n",
      "\n",
      "Epoch:    8/10    Loss: 3.062027053833008\n",
      "\n",
      "Epoch:    8/10    Loss: 3.0269030857086183\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9374921989440916\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8529593658447268\n",
      "\n",
      "Epoch:    8/10    Loss: 2.8376289939880373\n",
      "\n",
      "Epoch:    8/10    Loss: 2.9966021251678465\n",
      "\n",
      "Epoch:    8/10    Loss: 2.891129331588745\n",
      "\n",
      "Epoch:    8/10    Loss: 2.959148087501526\n",
      "\n",
      "Epoch:    8/10    Loss: 3.1278422451019288\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:    9/10    Loss: 3.12941996441331\n",
      "\n",
      "Epoch:    9/10    Loss: 3.150815210342407\n",
      "\n",
      "Epoch:    9/10    Loss: 2.6920596170425415\n",
      "\n",
      "Epoch:    9/10    Loss: 3.065137996673584\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8649161720275877\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9305105781555176\n",
      "\n",
      "Epoch:    9/10    Loss: 3.079547872543335\n",
      "\n",
      "Epoch:    9/10    Loss: 2.955148906707764\n",
      "\n",
      "Epoch:    9/10    Loss: 3.129499034881592\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9342377853393553\n",
      "\n",
      "Epoch:    9/10    Loss: 3.056912965774536\n",
      "\n",
      "Epoch:    9/10    Loss: 2.978582010269165\n",
      "\n",
      "Epoch:    9/10    Loss: 2.98243088722229\n",
      "\n",
      "Epoch:    9/10    Loss: 2.884348154067993\n",
      "\n",
      "Epoch:    9/10    Loss: 2.950247869491577\n",
      "\n",
      "Epoch:    9/10    Loss: 3.081778497695923\n",
      "\n",
      "Epoch:    9/10    Loss: 2.80159215927124\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0243101692199708\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9997437477111815\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9977224254608155\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9229065704345705\n",
      "\n",
      "Epoch:    9/10    Loss: 2.97064133644104\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0146995162963868\n",
      "\n",
      "Epoch:    9/10    Loss: 3.070632286071777\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0058645534515382\n",
      "\n",
      "Epoch:    9/10    Loss: 3.1307513332366943\n",
      "\n",
      "Epoch:    9/10    Loss: 2.927216691970825\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0559472846984863\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0367132663726806\n",
      "\n",
      "Epoch:    9/10    Loss: 2.83445818901062\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0353880977630614\n",
      "\n",
      "Epoch:    9/10    Loss: 2.938442544937134\n",
      "\n",
      "Epoch:    9/10    Loss: 3.269443464279175\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0592334270477295\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9688817405700685\n",
      "\n",
      "Epoch:    9/10    Loss: 2.818527326583862\n",
      "\n",
      "Epoch:    9/10    Loss: 2.835799903869629\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8350953102111816\n",
      "\n",
      "Epoch:    9/10    Loss: 2.870367364883423\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9461995697021486\n",
      "\n",
      "Epoch:    9/10    Loss: 2.77370924949646\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8062132167816163\n",
      "\n",
      "Epoch:    9/10    Loss: 2.93076681137085\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9169749355316164\n",
      "\n",
      "Epoch:    9/10    Loss: 3.2112148571014405\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0002119636535642\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8877245426177978\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0122696685791017\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8221311283111574\n",
      "\n",
      "Epoch:    9/10    Loss: 2.968243989944458\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9476012897491457\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0118286991119385\n",
      "\n",
      "Epoch:    9/10    Loss: 2.970370092391968\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9445313739776613\n",
      "\n",
      "Epoch:    9/10    Loss: 2.900485200881958\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8726014041900636\n",
      "\n",
      "Epoch:    9/10    Loss: 2.879614019393921\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8063677310943604\n",
      "\n",
      "Epoch:    9/10    Loss: 2.825373067855835\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8022446060180664\n",
      "\n",
      "Epoch:    9/10    Loss: 2.845015525817871\n",
      "\n",
      "Epoch:    9/10    Loss: 2.892491159439087\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8950586700439453\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7284005451202393\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7909925842285155\n",
      "\n",
      "Epoch:    9/10    Loss: 2.812721700668335\n",
      "\n",
      "Epoch:    9/10    Loss: 2.861813497543335\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9778573417663576\n",
      "\n",
      "Epoch:    9/10    Loss: 2.83750452041626\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8773968696594237\n",
      "\n",
      "Epoch:    9/10    Loss: 2.895182800292969\n",
      "\n",
      "Epoch:    9/10    Loss: 2.845267639160156\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8653191184997557\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8859496784210203\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9120047950744627\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8591096115112307\n",
      "\n",
      "Epoch:    9/10    Loss: 3.052042875289917\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8503622722625734\n",
      "\n",
      "Epoch:    9/10    Loss: 2.83583456993103\n",
      "\n",
      "Epoch:    9/10    Loss: 2.981739797592163\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8576829719543455\n",
      "\n",
      "Epoch:    9/10    Loss: 3.12463547706604\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9890620040893556\n",
      "\n",
      "Epoch:    9/10    Loss: 2.894617576599121\n",
      "\n",
      "Epoch:    9/10    Loss: 2.922646427154541\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7966486263275145\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8673112106323244\n",
      "\n",
      "Epoch:    9/10    Loss: 2.959041185379028\n",
      "\n",
      "Epoch:    9/10    Loss: 2.880169839859009\n",
      "\n",
      "Epoch:    9/10    Loss: 2.738610372543335\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8768521308898927\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7906277179718018\n",
      "\n",
      "Epoch:    9/10    Loss: 2.778194074630737\n",
      "\n",
      "Epoch:    9/10    Loss: 2.860006036758423\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9207302951812744\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9117493343353273\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8687205696105957\n",
      "\n",
      "Epoch:    9/10    Loss: 2.995367307662964\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8054940032958986\n",
      "\n",
      "Epoch:    9/10    Loss: 2.842072677612305\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9422818756103517\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8533786869049074\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8577073001861573\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9109026432037353\n",
      "\n",
      "Epoch:    9/10    Loss: 3.043370733261108\n",
      "\n",
      "Epoch:    9/10    Loss: 3.067568998336792\n",
      "\n",
      "Epoch:    9/10    Loss: 3.02493670463562\n",
      "\n",
      "Epoch:    9/10    Loss: 2.924797830581665\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7939539623260496\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9726811695098876\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9633631706237793\n",
      "\n",
      "Epoch:    9/10    Loss: 2.965986204147339\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9594965267181395\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9221928691864014\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9168655490875244\n",
      "\n",
      "Epoch:    9/10    Loss: 2.940155096054077\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0668200492858886\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9706147480010987\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0742838191986084\n",
      "\n",
      "Epoch:    9/10    Loss: 3.033262882232666\n",
      "\n",
      "Epoch:    9/10    Loss: 3.1076654243469237\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0796372413635256\n",
      "\n",
      "Epoch:    9/10    Loss: 3.119299783706665\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9971880435943605\n",
      "\n",
      "Epoch:    9/10    Loss: 2.88915376663208\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7999947929382323\n",
      "\n",
      "Epoch:    9/10    Loss: 2.942545976638794\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    9/10    Loss: 3.024244604110718\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0186448001861574\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8891765594482424\n",
      "\n",
      "Epoch:    9/10    Loss: 2.932784299850464\n",
      "\n",
      "Epoch:    9/10    Loss: 2.806267023086548\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9514266586303712\n",
      "\n",
      "Epoch:    9/10    Loss: 2.975758123397827\n",
      "\n",
      "Epoch:    9/10    Loss: 2.883191156387329\n",
      "\n",
      "Epoch:    9/10    Loss: 2.774852085113525\n",
      "\n",
      "Epoch:    9/10    Loss: 2.779380912780762\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8692523860931396\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8098456954956053\n",
      "\n",
      "Epoch:    9/10    Loss: 2.76672420501709\n",
      "\n",
      "Epoch:    9/10    Loss: 2.832266149520874\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7802035140991213\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7262729740142824\n",
      "\n",
      "Epoch:    9/10    Loss: 2.887703685760498\n",
      "\n",
      "Epoch:    9/10    Loss: 2.772450580596924\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9110805130004884\n",
      "\n",
      "Epoch:    9/10    Loss: 2.757266626358032\n",
      "\n",
      "Epoch:    9/10    Loss: 3.018036880493164\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8518111515045166\n",
      "\n",
      "Epoch:    9/10    Loss: 3.028685703277588\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0317284870147705\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9406596183776856\n",
      "\n",
      "Epoch:    9/10    Loss: 2.835351152420044\n",
      "\n",
      "Epoch:    9/10    Loss: 2.872447996139526\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8794630908966066\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9024408435821534\n",
      "\n",
      "Epoch:    9/10    Loss: 2.876232719421387\n",
      "\n",
      "Epoch:    9/10    Loss: 2.722440414428711\n",
      "\n",
      "Epoch:    9/10    Loss: 2.884110298156738\n",
      "\n",
      "Epoch:    9/10    Loss: 2.781021499633789\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7186147689819338\n",
      "\n",
      "Epoch:    9/10    Loss: 2.6737723922729493\n",
      "\n",
      "Epoch:    9/10    Loss: 2.862359743118286\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9328698253631593\n",
      "\n",
      "Epoch:    9/10    Loss: 2.769926137924194\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8928009128570555\n",
      "\n",
      "Epoch:    9/10    Loss: 2.90203893661499\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7550911998748777\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0226550197601316\n",
      "\n",
      "Epoch:    9/10    Loss: 2.771611204147339\n",
      "\n",
      "Epoch:    9/10    Loss: 2.677847843170166\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8914171695709228\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8728048515319826\n",
      "\n",
      "Epoch:    9/10    Loss: 2.796916742324829\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0243584728240966\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8587035179138183\n",
      "\n",
      "Epoch:    9/10    Loss: 2.734434461593628\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7786803817749024\n",
      "\n",
      "Epoch:    9/10    Loss: 2.664652080535889\n",
      "\n",
      "Epoch:    9/10    Loss: 2.94845046043396\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8776798248291016\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9299818801879884\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8885280323028564\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7408445358276365\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8406898975372314\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7804455757141113\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7878509998321532\n",
      "\n",
      "Epoch:    9/10    Loss: 2.913654298782349\n",
      "\n",
      "Epoch:    9/10    Loss: 2.949687042236328\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8224000453948976\n",
      "\n",
      "Epoch:    9/10    Loss: 2.891147518157959\n",
      "\n",
      "Epoch:    9/10    Loss: 2.6354088306427004\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8158647537231447\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8168222522735595\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0051846504211426\n",
      "\n",
      "Epoch:    9/10    Loss: 2.894289608001709\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8588020038604736\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7569509029388426\n",
      "\n",
      "Epoch:    9/10    Loss: 2.6490694522857665\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9115272045135496\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9681891632080077\n",
      "\n",
      "Epoch:    9/10    Loss: 2.971674098968506\n",
      "\n",
      "Epoch:    9/10    Loss: 2.988419761657715\n",
      "\n",
      "Epoch:    9/10    Loss: 2.958908996582031\n",
      "\n",
      "Epoch:    9/10    Loss: 3.057251272201538\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0503481674194335\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0502764797210693\n",
      "\n",
      "Epoch:    9/10    Loss: 2.881820821762085\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8680603599548338\n",
      "\n",
      "Epoch:    9/10    Loss: 2.821002712249756\n",
      "\n",
      "Epoch:    9/10    Loss: 2.850572147369385\n",
      "\n",
      "Epoch:    9/10    Loss: 3.1513398265838624\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0022537517547607\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9042717361450197\n",
      "\n",
      "Epoch:    9/10    Loss: 2.817408170700073\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8954874324798583\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9837162780761717\n",
      "\n",
      "Epoch:    9/10    Loss: 2.955437641143799\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8112088775634767\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9918652534484864\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9219348335266115\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9682190132141115\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8790121364593504\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0307813453674317\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9226208209991453\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8335946655273436\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9859014415740965\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9469518756866453\n",
      "\n",
      "Epoch:    9/10    Loss: 2.956427755355835\n",
      "\n",
      "Epoch:    9/10    Loss: 3.1062535572052004\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0538552093505857\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9052942180633545\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0425070190429686\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9323700523376464\n",
      "\n",
      "Epoch:    9/10    Loss: 2.850285806655884\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9937574672698974\n",
      "\n",
      "Epoch:    9/10    Loss: 2.973466701507568\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7391348457336426\n",
      "\n",
      "Epoch:    9/10    Loss: 2.979264268875122\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9647170639038087\n",
      "\n",
      "Epoch:    9/10    Loss: 3.044728889465332\n",
      "\n",
      "Epoch:    9/10    Loss: 2.909415912628174\n",
      "\n",
      "Epoch:    9/10    Loss: 2.922887773513794\n",
      "\n",
      "Epoch:    9/10    Loss: 2.953921022415161\n",
      "\n",
      "Epoch:    9/10    Loss: 2.963248109817505\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9003207731246947\n",
      "\n",
      "Epoch:    9/10    Loss: 3.009283771514893\n",
      "\n",
      "Epoch:    9/10    Loss: 2.935588779449463\n",
      "\n",
      "Epoch:    9/10    Loss: 2.826899251937866\n",
      "\n",
      "Epoch:    9/10    Loss: 2.845898094177246\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9543750953674315\n",
      "\n",
      "Epoch:    9/10    Loss: 3.209503583908081\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9525253486633303\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9133596324920656\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8329710292816164\n",
      "\n",
      "Epoch:    9/10    Loss: 2.827968978881836\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9914730644226073\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8983757400512697\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9090497970581053\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9167878913879393\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9689644241333006\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9264996337890623\n",
      "\n",
      "Epoch:    9/10    Loss: 2.866996717453003\n",
      "\n",
      "Epoch:    9/10    Loss: 3.084504804611206\n",
      "\n",
      "Epoch:    9/10    Loss: 3.0438429355621337\n",
      "\n",
      "Epoch:    9/10    Loss: 2.853539171218872\n",
      "\n",
      "Epoch:    9/10    Loss: 2.8107370948791504\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9030227661132812\n",
      "\n",
      "Epoch:    9/10    Loss: 2.992377519607544\n",
      "\n",
      "Epoch:    9/10    Loss: 2.932669038772583\n",
      "\n",
      "Epoch:    9/10    Loss: 2.940497236251831\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9027833461761476\n",
      "\n",
      "Epoch:    9/10    Loss: 2.7909241580963133\n",
      "\n",
      "Epoch:    9/10    Loss: 2.74883864402771\n",
      "\n",
      "Epoch:    9/10    Loss: 2.933040428161621\n",
      "\n",
      "Epoch:    9/10    Loss: 2.822276134490967\n",
      "\n",
      "Epoch:    9/10    Loss: 2.894591188430786\n",
      "\n",
      "Epoch:    9/10    Loss: 2.9863459396362306\n",
      "\n",
      "Model Trained and Saved\n",
      "Epoch:   10/10    Loss: 3.0366615750068844\n",
      "\n",
      "Epoch:   10/10    Loss: 3.0379058647155763\n",
      "\n",
      "Epoch:   10/10    Loss: 2.669980535507202\n",
      "\n",
      "Epoch:   10/10    Loss: 2.989405002593994\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7892369174957277\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8253818225860594\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9796039867401123\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8523184204101564\n",
      "\n",
      "Epoch:   10/10    Loss: 3.043822937011719\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8661730098724365\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9807086753845216\n",
      "\n",
      "Epoch:   10/10    Loss: 2.854568223953247\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9080438137054445\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8439494132995606\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8864219093322756\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9964831924438475\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8065875434875487\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9661090564727783\n",
      "\n",
      "Epoch:   10/10    Loss: 2.887481460571289\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9407247734069824\n",
      "\n",
      "Epoch:   10/10    Loss: 2.818055820465088\n",
      "\n",
      "Epoch:   10/10    Loss: 2.884371643066406\n",
      "\n",
      "Epoch:   10/10    Loss: 2.973287591934204\n",
      "\n",
      "Epoch:   10/10    Loss: 2.997814140319824\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9260906028747558\n",
      "\n",
      "Epoch:   10/10    Loss: 3.065341730117798\n",
      "\n",
      "Epoch:   10/10    Loss: 2.867250232696533\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9464477920532226\n",
      "\n",
      "Epoch:   10/10    Loss: 2.980044889450073\n",
      "\n",
      "Epoch:   10/10    Loss: 2.766633405685425\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9547592544555665\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8399926662445067\n",
      "\n",
      "Epoch:   10/10    Loss: 3.2018298149108886\n",
      "\n",
      "Epoch:   10/10    Loss: 3.002643566131592\n",
      "\n",
      "Epoch:   10/10    Loss: 2.896561441421509\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7689495658874512\n",
      "\n",
      "Epoch:   10/10    Loss: 2.768816547393799\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10/10    Loss: 2.72979229927063\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7914614295959472\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8475175857543946\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6859889698028563\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7396948528289795\n",
      "\n",
      "Epoch:   10/10    Loss: 2.883331546783447\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8484784507751466\n",
      "\n",
      "Epoch:   10/10    Loss: 3.120259780883789\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9111406326293947\n",
      "\n",
      "Epoch:   10/10    Loss: 2.814735326766968\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9161461448669432\n",
      "\n",
      "Epoch:   10/10    Loss: 2.764593172073364\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9268598461151125\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8636585521697997\n",
      "\n",
      "Epoch:   10/10    Loss: 2.913760166168213\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9139271450042723\n",
      "\n",
      "Epoch:   10/10    Loss: 2.881564903259277\n",
      "\n",
      "Epoch:   10/10    Loss: 2.851961431503296\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7876175117492674\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8117532920837403\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7334159660339354\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7453215503692627\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7671743869781493\n",
      "\n",
      "Epoch:   10/10    Loss: 2.744268455505371\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8202945470809935\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8573106956481933\n",
      "\n",
      "Epoch:   10/10    Loss: 2.62740159034729\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7453693675994875\n",
      "\n",
      "Epoch:   10/10    Loss: 2.757865352630615\n",
      "\n",
      "Epoch:   10/10    Loss: 2.767818880081177\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8778308486938475\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7676207542419435\n",
      "\n",
      "Epoch:   10/10    Loss: 2.781335687637329\n",
      "\n",
      "Epoch:   10/10    Loss: 2.78934760093689\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8020449542999266\n",
      "\n",
      "Epoch:   10/10    Loss: 2.790033903121948\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8228519344329834\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8716269588470458\n",
      "\n",
      "Epoch:   10/10    Loss: 2.73677188873291\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9597835636138914\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7814448165893553\n",
      "\n",
      "Epoch:   10/10    Loss: 2.749217233657837\n",
      "\n",
      "Epoch:   10/10    Loss: 2.874563150405884\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8024042415618897\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9898376083374023\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9156842708587645\n",
      "\n",
      "Epoch:   10/10    Loss: 2.82506667137146\n",
      "\n",
      "Epoch:   10/10    Loss: 2.84202278137207\n",
      "\n",
      "Epoch:   10/10    Loss: 2.69895751953125\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7530537700653075\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8749387645721436\n",
      "\n",
      "Epoch:   10/10    Loss: 2.803957061767578\n",
      "\n",
      "Epoch:   10/10    Loss: 2.68496337890625\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7637092018127443\n",
      "\n",
      "Epoch:   10/10    Loss: 2.725266580581665\n",
      "\n",
      "Epoch:   10/10    Loss: 2.702674083709717\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7933186531066894\n",
      "\n",
      "Epoch:   10/10    Loss: 2.782841329574585\n",
      "\n",
      "Epoch:   10/10    Loss: 2.855761709213257\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7637863540649414\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8967589569091796\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7702232360839845\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7758009815216065\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8578642082214354\n",
      "\n",
      "Epoch:   10/10    Loss: 2.803325901031494\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7807593059539797\n",
      "\n",
      "Epoch:   10/10    Loss: 2.889911470413208\n",
      "\n",
      "Epoch:   10/10    Loss: 2.960024003982544\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9643524646759034\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9728860092163085\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8488963985443116\n",
      "\n",
      "Epoch:   10/10    Loss: 2.721927080154419\n",
      "\n",
      "Epoch:   10/10    Loss: 2.875924196243286\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8964427375793456\n",
      "\n",
      "Epoch:   10/10    Loss: 2.866447048187256\n",
      "\n",
      "Epoch:   10/10    Loss: 2.88537127494812\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8089682483673095\n",
      "\n",
      "Epoch:   10/10    Loss: 2.831887845993042\n",
      "\n",
      "Epoch:   10/10    Loss: 2.843482723236084\n",
      "\n",
      "Epoch:   10/10    Loss: 2.962403373718262\n",
      "\n",
      "Epoch:   10/10    Loss: 2.878670253753662\n",
      "\n",
      "Epoch:   10/10    Loss: 2.996056890487671\n",
      "\n",
      "Epoch:   10/10    Loss: 2.945336256027222\n",
      "\n",
      "Epoch:   10/10    Loss: 3.0359545612335204\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9867835330963133\n",
      "\n",
      "Epoch:   10/10    Loss: 3.0364530658721924\n",
      "\n",
      "Epoch:   10/10    Loss: 2.907223148345947\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8338633441925047\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7003205585479737\n",
      "\n",
      "Epoch:   10/10    Loss: 2.879995460510254\n",
      "\n",
      "Epoch:   10/10    Loss: 2.969176950454712\n",
      "\n",
      "Epoch:   10/10    Loss: 2.92389105796814\n",
      "\n",
      "Epoch:   10/10    Loss: 2.831860132217407\n",
      "\n",
      "Epoch:   10/10    Loss: 2.832968902587891\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7768984127044676\n",
      "\n",
      "Epoch:   10/10    Loss: 2.847941904067993\n",
      "\n",
      "Epoch:   10/10    Loss: 2.905901050567627\n",
      "\n",
      "Epoch:   10/10    Loss: 2.805521287918091\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7123132610321044\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7548520946502686\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8216637325286866\n",
      "\n",
      "Epoch:   10/10    Loss: 2.727065124511719\n",
      "\n",
      "Epoch:   10/10    Loss: 2.723155040740967\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7314208126068116\n",
      "\n",
      "Epoch:   10/10    Loss: 2.693696279525757\n",
      "\n",
      "Epoch:   10/10    Loss: 2.646071443557739\n",
      "\n",
      "Epoch:   10/10    Loss: 2.799177875518799\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7154918670654298\n",
      "\n",
      "Epoch:   10/10    Loss: 2.857057466506958\n",
      "\n",
      "Epoch:   10/10    Loss: 2.672630672454834\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9159529876708983\n",
      "\n",
      "Epoch:   10/10    Loss: 2.82198016166687\n",
      "\n",
      "Epoch:   10/10    Loss: 2.944670305252075\n",
      "\n",
      "Epoch:   10/10    Loss: 2.966150884628296\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8638446521759033\n",
      "\n",
      "Epoch:   10/10    Loss: 2.782814455032349\n",
      "\n",
      "Epoch:   10/10    Loss: 2.75543776512146\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8116447734832763\n",
      "\n",
      "Epoch:   10/10    Loss: 2.823251485824585\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7685641479492187\n",
      "\n",
      "Epoch:   10/10    Loss: 2.70976957321167\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7869837951660155\n",
      "\n",
      "Epoch:   10/10    Loss: 2.717716722488403\n",
      "\n",
      "Epoch:   10/10    Loss: 2.5875972938537597\n",
      "\n",
      "Epoch:   10/10    Loss: 2.589749369621277\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7920785045623777\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8460264873504637\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7110361194610597\n",
      "\n",
      "Epoch:   10/10    Loss: 2.820645046234131\n",
      "\n",
      "Epoch:   10/10    Loss: 2.852500457763672\n",
      "\n",
      "Epoch:   10/10    Loss: 2.720098056793213\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9198410606384275\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6932955741882325\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6311474227905274\n",
      "\n",
      "Epoch:   10/10    Loss: 2.831200294494629\n",
      "\n",
      "Epoch:   10/10    Loss: 2.795017681121826\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7340309238433838\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9429866600036623\n",
      "\n",
      "Epoch:   10/10    Loss: 2.793343925476074\n",
      "\n",
      "Epoch:   10/10    Loss: 2.664832344055176\n",
      "\n",
      "Epoch:   10/10    Loss: 2.681131725311279\n",
      "\n",
      "Epoch:   10/10    Loss: 2.58640435218811\n",
      "\n",
      "Epoch:   10/10    Loss: 2.840463247299194\n",
      "\n",
      "Epoch:   10/10    Loss: 2.769022197723389\n",
      "\n",
      "Epoch:   10/10    Loss: 2.833083400726318\n",
      "\n",
      "Epoch:   10/10    Loss: 2.819643440246582\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7030005741119383\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7511900997161867\n",
      "\n",
      "Epoch:   10/10    Loss: 2.700196704864502\n",
      "\n",
      "Epoch:   10/10    Loss: 2.762386054992676\n",
      "\n",
      "Epoch:   10/10    Loss: 2.827584009170532\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8575704956054686\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7608070087432863\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7845117473602294\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6136800384521486\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7257211780548096\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7596287155151367\n",
      "\n",
      "Epoch:   10/10    Loss: 2.872939805984497\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7917300701141357\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7830201530456544\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6743489837646486\n",
      "\n",
      "Epoch:   10/10    Loss: 2.617639799118042\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8332771110534667\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8873700141906737\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8907527351379394\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9032582378387453\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8604238128662107\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9223546600341797\n",
      "\n",
      "Epoch:   10/10    Loss: 2.981531000137329\n",
      "\n",
      "Epoch:   10/10    Loss: 2.981178150177002\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7835995388031005\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7621390533447268\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7788981437683105\n",
      "\n",
      "Epoch:   10/10    Loss: 2.748297529220581\n",
      "\n",
      "Epoch:   10/10    Loss: 3.044700336456299\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9378853702545165\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7840807247161865\n",
      "\n",
      "Epoch:   10/10    Loss: 2.762357530593872\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8159705543518068\n",
      "\n",
      "Epoch:   10/10    Loss: 2.910006380081177\n",
      "\n",
      "Epoch:   10/10    Loss: 2.85264630317688\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7423649406433106\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9506599712371826\n",
      "\n",
      "Epoch:   10/10    Loss: 2.873346977233887\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8765271282196045\n",
      "\n",
      "Epoch:   10/10    Loss: 2.820724287033081\n",
      "\n",
      "Epoch:   10/10    Loss: 2.931207466125488\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8335878467559814\n",
      "\n",
      "Epoch:   10/10    Loss: 2.784445199966431\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   10/10    Loss: 2.8728575325012207\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8166943836212157\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8734183979034422\n",
      "\n",
      "Epoch:   10/10    Loss: 3.007222671508789\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9504487037658693\n",
      "\n",
      "Epoch:   10/10    Loss: 2.83138352394104\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9750442790985105\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8537125778198242\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7983189487457274\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8698663902282715\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8695687198638917\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6650820636749266\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8630099201202395\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9090867137908933\n",
      "\n",
      "Epoch:   10/10    Loss: 2.969241352081299\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8614719200134275\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8409281635284422\n",
      "\n",
      "Epoch:   10/10    Loss: 2.844747018814087\n",
      "\n",
      "Epoch:   10/10    Loss: 2.838493423461914\n",
      "\n",
      "Epoch:   10/10    Loss: 2.828055167198181\n",
      "\n",
      "Epoch:   10/10    Loss: 2.916692018508911\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8808339977264406\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7559346294403078\n",
      "\n",
      "Epoch:   10/10    Loss: 2.796118879318237\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9088725662231445\n",
      "\n",
      "Epoch:   10/10    Loss: 3.0399610424041748\n",
      "\n",
      "Epoch:   10/10    Loss: 2.915927448272705\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8250781059265138\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7569828128814695\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7431148433685304\n",
      "\n",
      "Epoch:   10/10    Loss: 2.911767063140869\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7854409980773926\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8016941261291506\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8447614669799806\n",
      "\n",
      "Epoch:   10/10    Loss: 2.861192626953125\n",
      "\n",
      "Epoch:   10/10    Loss: 2.794681167602539\n",
      "\n",
      "Epoch:   10/10    Loss: 2.742697877883911\n",
      "\n",
      "Epoch:   10/10    Loss: 3.0283474349975585\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9724629592895506\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7570455169677732\n",
      "\n",
      "Epoch:   10/10    Loss: 2.7309725093841553\n",
      "\n",
      "Epoch:   10/10    Loss: 2.842347526550293\n",
      "\n",
      "Epoch:   10/10    Loss: 2.938887023925781\n",
      "\n",
      "Epoch:   10/10    Loss: 2.863295431137085\n",
      "\n",
      "Epoch:   10/10    Loss: 2.867828826904297\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8044414043426515\n",
      "\n",
      "Epoch:   10/10    Loss: 2.6951589298248293\n",
      "\n",
      "Epoch:   10/10    Loss: 2.693216667175293\n",
      "\n",
      "Epoch:   10/10    Loss: 2.8774397659301756\n",
      "\n",
      "Epoch:   10/10    Loss: 2.797225875854492\n",
      "\n",
      "Epoch:   10/10    Loss: 2.797200336456299\n",
      "\n",
      "Epoch:   10/10    Loss: 2.9059303855895995\n",
      "\n",
      "Model Trained and Saved\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "\n",
    "# create model and move to gpu if available\n",
    "rnn = RNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, dropout=0.3)\n",
    "if train_on_gpu:\n",
    "    rnn.cuda()\n",
    "\n",
    "# defining loss and optimization functions for training\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trained_rnn = train_rnn(rnn, batch_size, optimizer, criterion, num_epochs, show_every_n_batches)\n",
    "\n",
    "# saving the trained model\n",
    "helper.save_model('./save/trained_rnn', trained_rnn)\n",
    "print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question: How did you decide on your model hyperparameters? \n",
    "For example, did you try different sequence_lengths and find that one size made the model converge faster? What about your hidden_dim and n_layers; how did you decide on those?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "It is observed that a larger sequence length helps to back propogate through longer time frame, and hence the networks ability develop long term memory improves. This helps in better losses, but the memory and time complexity increases with increase in this parameters. So as a trade off, 32 is selected. Another factor is, if the sequence length is a power of 2, the internal prcessor computations would be much faster. A gradual increment from 8 to 64, is made, and its found that beyond 64 it takes lot of time to complete the training.\n",
    "\n",
    "Large hidden dimentions will help the network to approximate complicated functions. Same logic as number of hidden layers in a FC network. However the backpropogation length increases, casusing extra memory and time ovrheads. A hidden dimention size of 1024 is decided, to get a trade off. Again , the parameter being power of 2 helps to improve processor coputation complexity\n",
    "\n",
    "Started with a learning rate of 0.0001, and tried to gradually improved the same. However, the larger learning rate tends oscillate the loss. Lower learning rates are almost not reducing the loss. So its found 0.001 is the best initial value. Adams would adaptively modify this rate internally.\n",
    "\n",
    "Number of epochs are selectd after observing  the validation, and training losses. The code for that is developed in PYCHARM IDE, and selected the point where the differences are small, and then both of them saturates. Currently it is set as 10, to achieve the required loss. However, its observed that higher number of epoches further reduces he loss, but will take hours to complete. 10 seems to be a better trade-off between the time and ojective in hand \n",
    "\n",
    "Number of layers are kept at 2, adding beyond that didnt seems to have any value addition to the performance\n",
    "\n",
    "Ideal choise of batch size may be 1, meaning we need to do a fw and bw propogation and adjust weight for evry single data. This is practically not possible. If we increase the batch size to infinity, the processr will have to deal with an infinite sized matrix dimentions. Furthermore, the accuracy of weight adjustments will be deteriorated. So as a tradeoff, a batch size of 128 is selected. \n",
    "Generally embedding dimentions are chosen between 200 to 300. Beyond that it would not give any significant improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Checkpoint\n",
    "\n",
    "After running the above training cell, your model will be saved by name, `trained_rnn`, and if you save your notebook progress, **you can pause here and come back to this code at another time**. You can resume your progress by running the next cell, which will load in our word:id dictionaries _and_ load in your saved model by name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\markkass\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\markkass\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\markkass\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "C:\\Users\\markkass\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\torch\\serialization.py:658: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import torch\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()\n",
    "trained_rnn = helper.load_model('./save/trained_rnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TV Script\n",
    "With the network trained and saved, you'll use it to generate a new, \"fake\" Seinfeld TV script in this section.\n",
    "\n",
    "### Generate Text\n",
    "To generate the text, the network needs to start with a single word and repeat its predictions until it reaches a set length. You'll be using the `generate` function to do this. It takes a word id to start with, `prime_id`, and generates a set length of text, `predict_len`. Also note that it uses topk sampling to introduce some randomness in choosing the most likely next word, given an output set of word scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m32\u001b[0m\n\u001b[1;33m    hidden = rnn.init_hidden(current_seq.size(0))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def generate(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len=100):\n",
    "    \"\"\"\n",
    "    Generate text using the neural network\n",
    "    :param decoder: The PyTorch Module that holds the trained neural network\n",
    "    :param prime_id: The word id to start the first prediction\n",
    "    :param int_to_vocab: Dict of word id keys to word values\n",
    "    :param token_dict: Dict of puncuation tokens keys to puncuation values\n",
    "    :param pad_value: The value used to pad a sequence\n",
    "    :param predict_len: The length of text to generate\n",
    "    :return: The generated text\n",
    "    \"\"\"\n",
    "    rnn.eval()\n",
    "    \n",
    "    # create a sequence (batch_size=1) with the prime_id\n",
    "    current_seq = np.full((1, sequence_length), pad_value)\n",
    "    current_seq[-1][-1] = prime_id\n",
    "    predicted = [int_to_vocab[prime_id]]\n",
    "    \n",
    "    for _ in range(predict_len):\n",
    "         current_seq = torch.LongTensor(current_seq)\n",
    "        if train_on_gpu:\n",
    "            current_seq = torch.LongTensor(current_seq).cuda()\n",
    "        else:\n",
    "            current_seq = torch.LongTensor(current_seq)\n",
    "        \n",
    "        # initialize the hidden state\n",
    "        hidden = rnn.init_hidden(current_seq.size(0))\n",
    "        \n",
    "        # get the output of the rnn\n",
    "        output, _ = rnn(current_seq, hidden)\n",
    "        \n",
    "        # get the next word probabilities\n",
    "        p = F.softmax(output, dim=1).data\n",
    "        if(train_on_gpu):\n",
    "            p = p.cpu() # move to cpu\n",
    "         \n",
    "        # use top_k sampling to get the index of the next word\n",
    "        top_k = 5\n",
    "        p, top_i = p.topk(top_k)\n",
    "        top_i = top_i.numpy().squeeze()\n",
    "        \n",
    "        # select the likely next word index with some element of randomness\n",
    "        p = p.numpy().squeeze()\n",
    "        word_i = np.random.choice(top_i, p=p/p.sum())\n",
    "        \n",
    "        # retrieve that word from the dictionary\n",
    "        word = int_to_vocab[word_i]\n",
    "        predicted.append(word)     \n",
    "        \n",
    "        # the generated word becomes the next \"current sequence\" and the cycle can continue\n",
    "        current_seq = np.roll(current_seq, -1, 1)\n",
    "        current_seq[-1][-1] = word_i\n",
    "    \n",
    "    gen_sentences = ' '.join(predicted)\n",
    "    \n",
    "    # Replace punctuation tokens\n",
    "    for key, token in token_dict.items():\n",
    "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
    "        gen_sentences = gen_sentences.replace(' ' + token.lower(), key)\n",
    "    gen_sentences = gen_sentences.replace('\\n ', '\\n')\n",
    "    gen_sentences = gen_sentences.replace('( ', '(')\n",
    "    \n",
    "    # return all the sentences\n",
    "    return gen_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a New Script\n",
    "It's time to generate the text. Set `gen_length` to the length of TV script you want to generate and set `prime_word` to one of the following to start the prediction:\n",
    "- \"jerry\"\n",
    "- \"elaine\"\n",
    "- \"george\"\n",
    "- \"kramer\"\n",
    "\n",
    "You can set the prime word to _any word_ in our dictionary, but it's best to start with a name for generating a TV script. (You can also start with any other names you find in the original text file!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-68a17c4d1704>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \"\"\"\n\u001b[0;32m      8\u001b[0m \u001b[0mpad_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhelper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSPECIAL_WORDS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PADDING'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgenerated_script\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrained_rnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprime_word\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m':'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint_to_vocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab_to_int\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpad_word\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_script\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-c022dfd8ee51>\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(rnn, prime_id, int_to_vocab, token_dict, pad_value, predict_len)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m# the generated word becomes the next \"current sequence\" and the cycle can continue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mcurrent_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[0mcurrent_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mroll\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mroll\u001b[1;34m(a, shift, axis)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \"\"\"\n\u001b[1;32m-> 1184\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mroll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \"\"\"\n\u001b[1;32m--> 136\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\spyderRnn\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    628\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelevant_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# run the cell multiple times to get different results!\n",
    "gen_length = 400 # modify the length to your preference\n",
    "prime_word = 'jerry' # name for starting the script\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "pad_word = helper.SPECIAL_WORDS['PADDING']\n",
    "generated_script = generate(trained_rnn, vocab_to_int[prime_word + ':'], int_to_vocab, token_dict, vocab_to_int[pad_word], gen_length)\n",
    "print(generated_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your favorite scripts\n",
    "\n",
    "Once you have a script that you like (or find interesting), save it to a text file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save script to a text file\n",
    "f =  open(\"generated_script_1.txt\",\"w\")\n",
    "f.write(generated_script)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The TV Script is Not Perfect\n",
    "It's ok if the TV script doesn't make perfect sense. It should look like alternating lines of dialogue, here is one such example of a few generated lines.\n",
    "\n",
    "### Example generated script\n",
    "\n",
    ">jerry: what about me?\n",
    ">\n",
    ">jerry: i don't have to wait.\n",
    ">\n",
    ">kramer:(to the sales table)\n",
    ">\n",
    ">elaine:(to jerry) hey, look at this, i'm a good doctor.\n",
    ">\n",
    ">newman:(to elaine) you think i have no idea of this...\n",
    ">\n",
    ">elaine: oh, you better take the phone, and he was a little nervous.\n",
    ">\n",
    ">kramer:(to the phone) hey, hey, jerry, i don't want to be a little bit.(to kramer and jerry) you can't.\n",
    ">\n",
    ">jerry: oh, yeah. i don't even know, i know.\n",
    ">\n",
    ">jerry:(to the phone) oh, i know.\n",
    ">\n",
    ">kramer:(laughing) you know...(to jerry) you don't know.\n",
    "\n",
    "You can see that there are multiple characters that say (somewhat) complete sentences, but it doesn't have to be perfect! It takes quite a while to get good results, and often, you'll have to use a smaller vocabulary (and discard uncommon words), or get more data.  The Seinfeld dataset is about 3.4 MB, which is big enough for our purposes; for script generation you'll want more than 1 MB of text, generally. \n",
    "\n",
    "# Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"dlnd_tv_script_generation.ipynb\" and save another copy as an HTML file by clicking \"File\" -> \"Download as..\"->\"html\". Include the \"helper.py\" and \"problem_unittests.py\" files in your submission. Once you download these files, compress them into one zip file for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
